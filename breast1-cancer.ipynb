{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88134f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d89572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('breast-cancer-wisconsin-data_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990d913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           int64\n",
       "diagnosis                   object\n",
       "radius_mean                float64\n",
       "texture_mean               float64\n",
       "perimeter_mean             float64\n",
       "area_mean                  float64\n",
       "smoothness_mean            float64\n",
       "compactness_mean           float64\n",
       "concavity_mean             float64\n",
       "concave points_mean        float64\n",
       "symmetry_mean              float64\n",
       "fractal_dimension_mean     float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worst               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1a06ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f19f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0.0\n",
       "diagnosis                  0.0\n",
       "radius_mean                0.0\n",
       "texture_mean               0.0\n",
       "perimeter_mean             0.0\n",
       "area_mean                  0.0\n",
       "smoothness_mean            0.0\n",
       "compactness_mean           0.0\n",
       "concavity_mean             0.0\n",
       "concave points_mean        0.0\n",
       "symmetry_mean              0.0\n",
       "fractal_dimension_mean     0.0\n",
       "radius_se                  0.0\n",
       "texture_se                 0.0\n",
       "perimeter_se               0.0\n",
       "area_se                    0.0\n",
       "smoothness_se              0.0\n",
       "compactness_se             0.0\n",
       "concavity_se               0.0\n",
       "concave points_se          0.0\n",
       "symmetry_se                0.0\n",
       "fractal_dimension_se       0.0\n",
       "radius_worst               0.0\n",
       "texture_worst              0.0\n",
       "perimeter_worst            0.0\n",
       "area_worst                 0.0\n",
       "smoothness_worst           0.0\n",
       "compactness_worst          0.0\n",
       "concavity_worst            0.0\n",
       "concave points_worst       0.0\n",
       "symmetry_worst             0.0\n",
       "fractal_dimension_worst    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fd6270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIXCAYAAABQCG65AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC7QklEQVR4nOzde1xN2f8/8Nfpdrrofm90I1JKohlyDenifs9lGteGjyEVhmYYtyGMIcZgGJeMMTUupTFNZCiMiiJiSIgGJUJJVGr9/ujX/jrOiU5nn3Tyfn4e+/Gptfd+r70wndXaa623gDHGQAghhBDSyCm97wcghBBCCKkL6rQQQgghRCFQp4UQQgghCoE6LYQQQghRCNRpIYQQQohCoE4LIYQQQhQCdVoIIYQQohCo00IIIYQQhUCdFkIIIYQoBOq0EEIIIUQhvNdOy6ZNm2Brawt1dXV07NgRp06dep+PQwghhJBG7L11WqKiohAUFISvv/4aFy5cQPfu3eHr64vc3Nz39UiEEEKIQpJmECAvLw9jx46Fvb09lJSUEBQUJPG6AwcOwNHREUKhEI6OjoiOjpapXj68t07L2rVrMXnyZEyZMgUODg4IDw+HpaUlNm/e/L4eiRBCCFE40g4ClJWVwdjYGF9//TVcXFwkXpOcnAw/Pz/4+/vj4sWL8Pf3x6hRo5CamlrvevkgeB9ZnsvLy6GpqYl9+/Zh6NChXPmsWbOQkZGBpKSkhn4kQgghRCF16tQJHTp0EPml38HBAUOGDEFYWNhb7/Xw8ED79u0RHh4uUu7n54fi4mL89ddfXJmPjw/09fXx22+/yVxvfb2XkZZHjx6hsrISpqamIuWmpqbIz88Xu76srAzFxcUiR1lZWUM9LiGEENJgpPnMKy8vR3p6Ory8vETKvby8cObMmXo/Q3JyslhMb29vLqa86n0XFblFrgOBQCDyPWNMrAwAwsLCsGTJEpGyAG17fK7TRq7PRwghpGlwuxsj9zoqHt3iJU7Yxt1in3mLFi3C4sWLxa6VdhCgrvLz898aU171vst76bQYGRlBWVlZrGEFBQVifwAAEBoaipCQEJGyyw7j5PqMhBBCiFSqKnkJI+kzTygUvvWeug4CSKMuMeVR79u8l06LmpoaOnbsiISEBJE5LQkJCRg8eLDY9UKhUOwvTE2gLPfnJIQQQhqapM+82kg7CFBXZmZmb40pr3rf5b2tHgoJCcHPP/+MHTt24OrVqwgODkZubi6mTZv2vh6JEEIIqT9Wxc8hhdcHAV6XkJCALl261Lsp7u7uYjGPHj3KxZRXve/y3ua0+Pn5obCwEEuXLkVeXh6cnJwQFxcHa2vr9/VIhBBCSP1VSdfh4EtISAj8/f3h5uYGd3d3bN26VWQQIDQ0FPfu3cPu3bu5ezIyMgAAJSUlePjwITIyMqCmpgZHR0cA1at5e/TogVWrVmHw4ME4dOgQjh07htOnT9e5Xnl4L0ue+ZDWfMj7fgRCCCEKokEm4uZd5SWOqrmD1Pds2rQJq1ev5gYB1q1bhx49egAAJkyYgNu3byMxMZG7XtK8E2tra9y+fZv7fv/+/ViwYAFu3bqFli1bYvny5Rg2bFid65UH6rQQQghp8hqi01J+/wovcdQs2vISpyl6r0ueCSGEkCbjPb0e+pBQlmdCCCGEKATeOy1hYWH4+OOPoa2tDRMTEwwZMgRZWVnc+YqKCsybNw/Ozs7Q0tKChYUFPvvsM9y/f5/vRyGEEEIazntYPfSh4b3TkpSUhC+++AIpKSlISEjAq1ev4OXlhefPnwMASktLcf78eSxcuBDnz5/HwYMHcf36dQwaNIjvRyGEEEIaTlUlPwepldwn4j58+BAmJiZISkqqdUbxuXPn8Mknn+DOnTuwsrKqU1yaiEsIIaSuGmQi7u00XuKo2bjxEqcpkvuclqKiIgCAgYHBW68RCATQ09OT9+MQQgghREHJdfUQYwwhISHo1q0bnJycJF7z8uVLzJ8/H2PHjoWOjo48H4cQQgiRH1o9JHdy7bTMmDEDly5dEtlB73UVFRUYPXo0qqqqsGnTplrjlJWViaXlLmeVlH+IEEJIo8FoEq3cye310MyZMxEbG4sTJ06gefPmYucrKiowatQo5OTkICEh4a2jLGFhYdDV1RU5dj3LltejE0IIIaQR4n0iLmMMM2fORHR0NBITE9GqVSuxa2o6LNnZ2Thx4gSMjY3fGlPSSMtlh3E00kIIIaROGmIibln2GV7iCFvJL+GgouP99dAXX3yBvXv34tChQ9DW1ubSVuvq6kJDQwOvXr3CiBEjcP78eRw+fBiVlZXcNQYGBlBTUxOLKSlNN3VYCCGENCr0ekjueB9pkZSECQB27tzJJW2ytbWVeM2JEyfg4eFRp3poyTMhhJC6apCRluuS529KS9i6Gy9xmiLeR1re1QeysbF55zWEEEKIwqGN4eSOEiYSQgghfKDXQ3JHCRMJIYQQohBopIUQQgjhA20uJ3fUaSGEEEL4QK+H5E7ur4fCwsIgEAgQFBQk8fzUqVMhEAgQHh4u70chhBBC5Keqip+D1EqunZZz585h69ataNeuncTzMTExSE1NhYWFhTwfgxBCCCFNgNw6LSUlJRg3bhy2bdsGfX19sfP37t3DjBkz8Ouvv0JVVVVej0EIIYQ0CMYqeTlI7eTWafniiy/Qv39/eHp6ip2rqqqCv78/5s6di7Zt28rrEQghhJCGw6r4OUit5DIRNzIyEufPn8e5c+cknl+1ahVUVFQQGBhYp3iU5ZkQQgghvI+0/Pfff5g1axb27NkDdXV1sfPp6elYv349du3aVeuW/2+iLM+EEEIaPZqIK3e85x6KiYnB0KFDoaz8f6MglZWVEAgEUFJSwqpVqzB37lwoKSmJnFdSUoKlpSVu374tFpOyPBNCCJFFQ+QeepnOTx3qHYfwEqcp4v31UJ8+fZCZmSlSNnHiRLRp0wbz5s2Dubk5vL29Rc57e3vD398fEydOlBiTsjwTQgghhPdOi7a2NpycnETKtLS0YGhoyJUbGhqKnFdVVYWZmRns7e35fhxCCCGkYVDCRLmjHXEJIYQQPtDKH7lrkE5LYmLiW89LmsdCCCGEEPI6GmkhhBBC+EArf+SOOi2EEEIIH+j1kNxRp4UQQgjhA420yJ1ctvG/d+8ePv30UxgaGkJTUxPt27dHenq6yDVXr17FoEGDoKurC21tbXTu3Bm5ubnyeBxCCCGENAG8j7Q8efIEXbt2Ra9evfDXX3/BxMQEN2/ehJ6eHnfNzZs30a1bN0yePBlLliyBrq4url69KnEHXUIIIUQh0EiL3PHeaVm1ahUsLS2xc+dOrszGxkbkmq+//hr9+vXD6tWrubIWLVrw/SiEEEJIg6EMzfLH++uh2NhYuLm5YeTIkTAxMYGrqyu2bdvGna+qqsKff/6J1q1bw9vbGyYmJujUqRNiYmL4fhRCCCGENCG8d1pu3bqFzZs3o1WrVjhy5AimTZuGwMBA7N69GwBQUFCAkpISrFy5Ej4+Pjh69CiGDh2KYcOGISkpSWLMsrIyFBcXixzl1KMlhBDSmLzHhImbNm2Cra0t1NXV0bFjR5w6deqt1yclJaFjx45QV1dHixYtsGXLFpHzHh4eEAgEYkf//v25axYvXix23szMrF7PX1e8vx6qqqqCm5sbVqxYAQBwdXXFlStXsHnzZnz22Weo+v9/IYMHD0ZwcDAAoH379jhz5gy2bNmCnj17isUMCwvDkiVLRMoCtO3xuU4bvh+fEEIIqZ/3tOQ5KioKQUFB2LRpE7p27YqffvoJvr6++Pfff2FlZSV2fU5ODvr164eAgADs2bMH//zzD6ZPnw5jY2MMHz4cAHDw4EGUl5dz9xQWFsLFxQUjR44UidW2bVscO3aM+/71ZMnywPtIi7m5ORwdHUXKHBwcuJVBRkZGUFFRees1bwoNDUVRUZHIMUG7Fd+PTgghhCictWvXYvLkyZgyZQocHBwQHh4OS0tLbN68WeL1W7ZsgZWVFcLDw+Hg4IApU6Zg0qRJWLNmDXeNgYEBzMzMuCMhIQGamppinRYVFRWR64yNjeXaVt47LV27dkVWVpZI2fXr12FtbQ0AUFNTw8cff/zWa94kFAqho6MjclCWZ0IIIY0KT6+HJE2JKCsrk1hleXk50tPT4eXlJVLu5eWFM2fOSLwnOTlZ7Hpvb2+kpaWhoqJC4j3bt2/H6NGjoaWlJVKenZ0NCwsL2NraYvTo0bh161Zd/7TqhfdOS3BwMFJSUrBixQrcuHEDe/fuxdatW/HFF19w18ydOxdRUVHYtm0bbty4gY0bN+KPP/7A9OnT+X4cQgghpGGwKl6OsLAw6OrqihxhYWESq3z06BEqKythamoqUm5qaor8/HyJ9+Tn50u8/tWrV3j06JHY9WfPnsXly5cxZcoUkfJOnTph9+7dOHLkCLZt24b8/Hx06dIFhYWF0vypSYX3OS0ff/wxoqOjERoaiqVLl8LW1hbh4eEYN24cd83QoUOxZcsWhIWFITAwEPb29jhw4AC6devG9+MQQgghCiU0NBQhISEiZUKh8K33CAQCke8ZY2Jl77peUjlQPcri5OSETz75RKTc19eX+9rZ2Rnu7u5o2bIlIiIixJ6fL3LZxn/AgAEYMGDAW6+ZNGkSJk2aJI/qCSGEkIbH0+ZyQqHwnZ2UGkZGRlBWVhYbVSkoKBAbTalhZmYm8XoVFRUYGhqKlJeWliIyMhJLly5957NoaWnB2dkZ2dnZdXr2+pDLNv6EEELIB4en10PSUFNTQ8eOHZGQkCBSnpCQgC5duki8x93dXez6o0ePws3NDaqqqiLlv//+O8rKyvDpp5++81nKyspw9epVmJubS9UGaVCnhRBCCOHDe9qnJSQkBD///DN27NiBq1evIjg4GLm5uZg2bRqA6tdNn332GXf9tGnTcOfOHYSEhODq1avYsWMHtm/fjjlz5ojF3r59O4YMGSI2AgMAc+bMQVJSEnJycpCamooRI0aguLgY48ePl7oNdUVZngkhhBAF5ufnh8LCQixduhR5eXlwcnJCXFwctyI3Ly9PZEsRW1tbxMXFITg4GD/++CMsLCywYcMGbo+WGtevX8fp06dx9OhRifXevXsXY8aMwaNHj2BsbIzOnTsjJSWl1pXAfBCwmtk3PHn16hUWL16MX3/9Ffn5+TA3N8eECROwYMECKClVD+yUlJRg/vz5iImJQWFhIWxsbBAYGIj//e9/da4nrfkQPh+bEEJIE+Z2N0budbz4M5yXOBr9g3iJ0xTJJWHili1bEBERgbZt2yItLQ0TJ06Erq4uZs2aBaB6WfSJEyewZ88e2NjY4OjRo5g+fTosLCwwePBgvh+JEEIIkb/3tCPuh4T3OS3JyckYPHgw+vfvDxsbG4wYMQJeXl5IS0sTuWb8+PHw8PCAjY0NPv/8c7i4uIhcQwghhBDyOt47Ld26dcPff/+N69evAwAuXryI06dPo1+/fiLXxMbG4t69e2CM4cSJE7h+/Tq8vb35fhxCCCGkYbzHhIkfCt5fD82bNw9FRUVo06YNlJWVUVlZieXLl2PMmDHcNRs2bEBAQACaN28OFRUVKCkp4eeff651c7mysjKxLYzLWSVt5U8IIaTxoNdDcsf7SEtUVBT27NmDvXv34vz584iIiMCaNWsQERHBXbNhwwakpKQgNjYW6enp+P777zF9+nSRTJGvk7Sl8a5n8tu8hhBCCCGND++rhywtLTF//nyRXEPffvst9uzZg2vXruHFixfQ1dVFdHQ0+vfvz10zZcoU3L17F/Hx8WIxJY20XHYYRyMthBBC6qRBVg9Fr+QljsbQ+bzEaYp4fz1UWlrKLW2uoaysjKr//56uoqICFRUVb73mTZK2NKYOCyGEkEaFXg/JHe+dloEDB2L58uWwsrJC27ZtceHCBaxdu5bLM6Sjo4OePXti7ty50NDQgLW1NZKSkrB7926sXbuW78chhBBCSBPBe6flhx9+wMKFCzF9+nQUFBTAwsICU6dOxTfffMNdExkZidDQUIwbNw6PHz+GtbU1li9fzm05TAghhCgcWvkjd7zPaWkotCMuIYSQumqQOS2/vzsTcl1ojPrm3Rd9oCj3ECGEEMIHxRwDUCiU5ZkQQgghCoFGWgghhBA+0JwWuZN6pOXkyZMYOHAgLCwsIBAIEBMTI3L+4MGD8Pb2hpGREQQCATIyMsRilJWVYebMmTAyMoKWlhYGDRqEu3fv1rcNhBBCyPtH2/jLndSdlufPn8PFxQUbN26s9XzXrl2xcmXtm+wEBQUhOjoakZGROH36NEpKSjBgwABUVlZK+ziEEEII+UBI/XrI19cXvr6+tZ739/cHANy+fVvi+aKiImzfvh2//PILPD09AQB79uyBpaUljh07RkkTCSGEKCbaXE7uGnwibnp6OioqKuDl5cWVWVhYwMnJCWfOnGnoxyGEEEL4Qa+H5K7BOy35+flQU1ODvr6+SLmpqSny8/Mb+nEIIYQQoiAazeohxhgEAoHEc5ISJpazSso/RAghpPGgfVrkrsFHWszMzFBeXo4nT56IlBcUFMDU1FTiPWFhYdDV1RU5dj3LbojHJYQQQuqGXg/JXYN3Wjp27AhVVVUkJCRwZXl5ebh8+TK6dOki8Z7Q0FAUFRWJHBO0WzXUIxNCCCGkEZD69VBJSQlu3LjBfZ+Tk4OMjAwYGBjAysoKjx8/Rm5uLu7fvw8AyMrKAlA9wmJmZgZdXV1MnjwZs2fPhqGhIQwMDDBnzhw4Oztzq4neJBQKIRQKRcro1RAhhJBGhUZJ5E7qTktaWhp69erFfR8SEgIAGD9+PHbt2oXY2FhMnDiROz969GgAwKJFi7B48WIAwLp166CiooJRo0bhxYsX6NOnD3bt2gVlZeqIEEIIUVC05FnuKMszIYSQJq8hsjyXbg3mJY7m5+t4idMUUcJEQgghhCiERrPkmRBCCFFoNKdF7qjTQgghhPCB5rTIHb0eIoQQQohCkLrTcvLkSQwcOBAWFhYQCASIiYkROb948WK0adMGWlpa0NfXh6enJ1JTU7nzjx8/xsyZM2Fvbw9NTU1YWVkhMDAQRUVFMjeGEEIIeW+qGD8HqZXUnZbnz5/DxcUFGzdulHi+devW2LhxIzIzM3H69GnY2NjAy8sLDx8+BADcv38f9+/fx5o1a5CZmYldu3YhPj4ekydPlq0lhBBCyPtEO+LKnUxLngUCAaKjozFkyJBarykuLoauri6OHTuGPn36SLxm3759+PTTT/H8+XOoqNRtmg0teSaEEFJXDbLk+YfpvMTRnLmJlzhNkVwn4paXl2Pr1q3Q1dWFi4tLrdcVFRVBR0enzh0WQgghpNGhURK5k0sv4fDhwxg9ejRKS0thbm6OhIQEGBkZSby2sLAQy5Ytw9SpU2uNR1meCSGENHqKuVerQpHL6qFevXohIyMDZ86cgY+PD0aNGoWCggKx64qLi9G/f384Ojpi0aJFtcajLM+EEEIIkUunRUtLC3Z2dujcuTO2b98OFRUVbN++XeSaZ8+ewcfHB82aNUN0dDRUVVVrjUdZngkhhDR6NBFX7hpkEgljTOT1TnFxMby9vSEUChEbGwt1dfW33k9ZngkhhDR6tFxZ7qQeaSkpKUFGRgYyMjIAADk5OcjIyEBubi6eP3+Or776CikpKbhz5w7Onz+PKVOm4O7duxg5ciSA6hEWLy8vPH/+HNu3b0dxcTHy8/ORn5+PyspKXhtHCCGENBhWxc9RD5s2bYKtrS3U1dXRsWNHnDp16q3XJyUloWPHjlBXV0eLFi2wZcsWkfO7du2CQCAQO16+fClTvbKSutOSlpYGV1dXuLq6AgBCQkLg6uqKb775BsrKyrh27RqGDx+O1q1bY8CAAXj48CFOnTqFtm3bAgDS09ORmpqKzMxM2NnZwdzcnDv+++8/fltHCCGENHFRUVEICgrC119/jQsXLqB79+7w9fVFbm6uxOtzcnLQr18/dO/eHRcuXMBXX32FwMBAHDhwQOQ6HR0d5OXliRyvvxmRtl4+yLRPy/tE+7QQQgipqwbZp2XVRF7iKAdtEVsxK2maRI1OnTqhQ4cO2Lx5M1fm4OCAIUOGICwsTOz6efPmITY2FlevXuXKpk2bhosXLyI5ORlA9UhLUFAQnj59WutzSlsvHyj3ECGEEMIDVlXFyyFpxWxtnYDy8nKkp6fDy8tLpNzLywtnzpyReE9ycrLY9d7e3khLS0NFRQVXVlJSAmtrazRv3hwDBgzAhQsXZKqXD9RpIYQQQhoRSStmQ0NDJV776NEjVFZWwtTUVKTc1NQU+fn5Eu/Jz8+XeP2rV6/w6NEjAECbNm2wa9cuxMbG4rfffoO6ujq6du2K7OzsetfLB9qClhBCCOEDT6uH3vYqqDYCgUDke8aYWNm7rn+9vHPnzujcuTN3vmvXrujQoQN++OEHbNiwod71yor3LM8TJkwQm238esNfxxiDr6+vxDiEEEKIQnkPq4eMjIygrKwsNrpRUFAgNgpSw8zMTOL1KioqMDQ0lHiPkpISPv74Y26kpT718oH3LM8A4OPjIzLbOC4uTuJ14eHhcu2REUIIIU2ZmpoaOnbsiISEBJHyhIQEdOnSReI97u7uYtcfPXoUbm5utW70yhhDRkYGzM3N610vH6R+PeTr6wtfX9+3XiMUCmFmZvbWay5evIi1a9fi3Llz3B8CIYQQorDe0+ZyISEh8Pf3h5ubG9zd3bF161bk5uZi2rRpAKrnyNy7dw+7d+8GUL1SaOPGjQgJCUFAQACSk5Oxfft2/Pbbb1zMJUuWoHPnzmjVqhWKi4uxYcMGZGRk4Mcff6xzvfIglzktiYmJMDExgZ6eHnr27Inly5fDxMSEO19aWooxY8Zg48aN7+zcEEIIIQrhPW3B7+fnh8LCQixduhR5eXlwcnJCXFwcrK2tAQB5eXkie6fY2toiLi4OwcHB+PHHH2FhYYENGzZg+PDh3DVPnz7F559/jvz8fOjq6sLV1RUnT57EJ598Uud65UGmfVoEAgGio6MxZMgQriwqKgrNmjWDtbU1cnJysHDhQrx69Qrp6encxKKpU6eisrISP//8c61xXicpy/Nlh3G0lT8hhJA6aYh9Wp4vHsNLHK3Fv737og8U7yMtfn5+3NdOTk5wc3ODtbU1/vzzTwwbNgyxsbE4fvy4yHrvdwkLC8OSJUtEygK07fG5ThvenpsQQgiRCeUekju579Nibm4Oa2trbsbx8ePHcfPmTejp6UFFRQUqKtX9puHDh8PDw0NiDMryTAghpNF7j7mHPhRy36elsLAQ//33HzfZdv78+ZgyZYrINc7Ozli3bh0GDhwoMQZleSaEENLo0UiL3EndaSkpKcGNGze472uyPBsYGMDAwACLFy/G8OHDYW5ujtu3b+Orr76CkZERhg4dCqB6fbikybdWVlawtbWVoSmEEEIIacqk7rSkpaWhV69e3PchISEAgPHjx2Pz5s3IzMzE7t278fTpU5ibm6NXr16IioqCtrY2f09NCCGENDLsPa0e+pBI3Wnx8PDA2xYcHTlyROqHUNBE04QQQsj/oddDckcJEwkhhBCiEChhIiGEEMIHGmmRO+q0EEIIIXyg5cpyx3uW5zczPNcc3333nch1ycnJ6N27N7S0tKCnpwcPDw+8ePFCpsYQQgghpOniPcvz69md8/LysGPHDggEApGcBsnJyfDx8YGXlxfOnj2Lc+fOYcaMGVBSoik2hBBCFFQV4+cgteI9y/Obe7AcOnQIvXr1QosWLbiy4OBgBAYGYv78+VxZq1a0wy0hhBDFxajDIXdyHdp48OAB/vzzT0yePJkrKygoQGpqKkxMTNClSxeYmpqiZ8+eOH36tDwfhRBCCCEKTq6dloiICGhra2PYsGFc2a1btwAAixcvRkBAAOLj49GhQwf06dOHy09ECCGEKBx6PSR3cl09tGPHDowbNw7q6upcWdX/3zFw6tSpmDhxIgDA1dUVf//9N3bs2IGwsDCxOGVlZSgrKxMpK2eVlH+IEEJI40E74sqd3EZaTp06haysLLHkiDWJEx0dHUXKHRwckJubKzFWWFgYdHV1RY5dz2hUhhBCSCNCIy1yJ7dOy/bt29GxY0e4uLiIlNvY2MDCwgJZWVki5devX4e1tbXEWKGhoSgqKhI5JmjTxF1CCCHkQ8JrlmcrKysAQHFxMfbt24fvv/9e7H6BQIC5c+di0aJFcHFxQfv27REREYFr165h//79EusUCoUQCoUiZfRqiBBCSKNCoyRyx2uW5127dgEAIiMjwRjDmDFjJMYICgrCy5cvERwcjMePH8PFxQUJCQlo2bJlPZpACCGEvH+U/Ff+BExB/5TTmg95349ACCFEQbjdjZF7HcVTvXmJo/PTEV7iNEWUe4gQQgjhA70ekjvqtBBCCCF8oE6L3FGyH0IIIYQoBBppIYQQQnhAuYfkT+qRlpMnT2LgwIGwsLCAQCBATEyMyPkHDx5gwoQJsLCwgKamJnx8fMS258/Pz4e/vz/MzMygpaWFDh061LrcmRBCCFEItLmc3EndaXn+/DlcXFywceNGsXOMMQwZMgS3bt3CoUOHcOHCBVhbW8PT0xPPnz/nrvP390dWVhZiY2ORmZmJYcOGwc/PDxcuXJCtNYQQQghpsqR+PeTr6wtfX1+J57Kzs5GSkoLLly+jbdu2AIBNmzbBxMQEv/32G7elf3JyMjZv3oxPPvkEALBgwQKsW7cO58+fh6ura33bQgghhLw/lHpI7nidiFuT1PD1BInKyspQU1PD6dOnubJu3bohKioKjx8/RlVVFSIjI1FWVgYPDw8+H4cQQghpMKyK8XKQ2vHaaWnTpg2sra0RGhqKJ0+eoLy8HCtXrkR+fj7y8vK466KiovDq1SsYGhpCKBRi6tSpiI6OrnVH3LKyMhQXF4sc5aySz0cnhBBCZENzWuSO106LqqoqDhw4gOvXr8PAwACamppITEyEr68vlJX/L1fQggUL8OTJExw7dgxpaWkICQnByJEjkZmZKTEuZXkmhBBCiEzb+AsEAkRHR2PIkCFi54qKilBeXg5jY2N06tQJbm5u+PHHH3Hz5k3Y2dmJzHsBAE9PT9jZ2WHLli1iscrKyrhXTzUuO4yjpImEEELqpCG28X/q1+vdF9WBXtQJXuI0RXLbp0VXVxdA9eTctLQ0LFu2DABQWloKAFBSEh3kUVZWRlWV5FlMlOWZEEJIY0fzUeRP6k5LSUkJbty4wX2fk5ODjIwMGBgYwMrKCvv27YOxsTGsrKyQmZmJWbNmYciQIfDy8gJQPe/Fzs4OU6dOxZo1a2BoaIiYmBgkJCTg8OHD/LWMEEIIIU2K1J2WtLQ09Or1f0NgISEhAIDx48dj165dyMvLQ0hICB48eABzc3N89tlnWLhwIXe9qqoq4uLiMH/+fAwcOBAlJSWws7NDREQE+vXrx0OTCCGEkPeAljzLnUxzWt6ntOZD3vcjEEIIURANMafl8dCevMQxiE7iJU5TRAkTCSGEEAW3adMm2NraQl1dHR07dsSpU6feen1SUhI6duwIdXV1tGjRQmwRzLZt29C9e3fo6+tDX18fnp6eOHv2rMg1ixcvhkAgEDnMzMx4b9vrqNNCCCGE8KGKp0NKUVFRCAoKwtdff40LFy6ge/fu8PX1RW5ursTrc3Jy0K9fP3Tv3h0XLlzAV199hcDAQBw4cIC7JjExEWPGjMGJEyeQnJwMKysreHl54d69eyKx2rZti7y8PO6obesSvtDrIUIIIU1eQ7weKhzIz+shwz+kez3UqVMndOjQAZs3b+bKHBwcMGTIEISFhYldP2/ePMTGxuLq1atc2bRp03Dx4kUkJydLrKOyshL6+vrYuHEjPvvsMwDVIy0xMTHIyMiQ6nllIdVIS1hYGD7++GNoa2vDxMQEQ4YMQVZWFne+oqIC8+bNg7OzM7S0tGBhYYHPPvsM9+/fF4lTVlaGmTNnwsjICFpaWhg0aBDu3r3LT4sIIYQQBSZpF/g39yqrUV5ejvT0dG6Fbg0vLy+cOXNG4j3Jycli13t7eyMtLQ0VFRUS7yktLUVFRQUMDAxEyrOzs2FhYQFbW1uMHj0at27dqmsz60WqTktSUhK++OILpKSkICEhAa9evYKXlxeXwbm0tBTnz5/HwoULcf78eRw8eBDXr1/HoEGDROIEBQUhOjoakZGROH36NEpKSjBgwABUVtLW/IQQQhQUT6+HJO0CL2nEBAAePXqEyspKmJqaipSbmpoiPz9f4j35+fkSr3/16hUePXok8Z758+fjo48+gqenJ1fWqVMn7N69G0eOHMG2bduQn5+PLl26oLCw8C1/SLKRaslzfHy8yPc7d+6EiYkJ0tPT0aNHD+jq6iIhIUHkmh9++AGffPIJcnNzYWVlhaKiImzfvh2//PIL1/g9e/bA0tISx44dg7e3t4xNIoQQQhoe42nJc2hoKLedSI03N1h9k0AgEH0WxsTK3nW9pHIAWL16NX777TckJiaKJET29fXlvnZ2doa7uztatmyJiIgIsefni0wTcYuKigBAbLjozWsEAgH09PQAAOnp6aioqBAZmrKwsICTk1OtQ1mEEEJIo8fTSItQKISOjo7IUVunxcjICMrKymKjKgUFBWKjKTXMzMwkXq+iogJDQ0OR8jVr1mDFihU4evQo2rVr99bma2lpwdnZGdnZ8ssNWO9OC2MMISEh6NatG5ycnCRe8/LlS8yfPx9jx46Fjo4OgOphKTU1Nejr64tc+7ahLMryTAghhIhTU1NDx44dxd5yJCQkoEuXLhLvcXd3F7v+6NGjcHNzg6qqKlf23XffYdmyZYiPj4ebm9s7n6WsrAxXr16Fubl5PVpSN/XutMyYMQOXLl3Cb7/9JvF8RUUFRo8ejaqqKmzatOmd8d42lEVZngkhhDR2rIqfQ1ohISH4+eefsWPHDly9ehXBwcHIzc3FtGnTAFS/bqpZ8QNUrxS6c+cOQkJCcPXqVezYsQPbt2/HnDlzuGtWr16NBQsWYMeOHbCxsUF+fj7y8/NRUlLCXTNnzhwkJSUhJycHqampGDFiBIqLizF+/Pj6/yG+Q706LTNnzkRsbCxOnDiB5s2bi52vqKjAqFGjkJOTg4SEBG6UBageliovL8eTJ09E7nnbUFZoaCiKiopEjgnarerz6IQQQohcvK9Oi5+fH8LDw7F06VK0b98eJ0+eRFxcHKytrQEAeXl5Inu22NraIi4uDomJiWjfvj2WLVuGDRs2YPjw4dw1mzZtQnl5OUaMGAFzc3PuWLNmDXfN3bt3MWbMGNjb22PYsGFQU1NDSkoKV688SLVPC2MMM2fORHR0NBITE9GqlXjHoabDkp2djRMnTsDY2FjkfFFREYyNjbFnzx6MGjUKQPUfaPPmzREXF1fnibi0TwshhJC6aoh9Wgr68LNPi8nftI1/baRaPfTFF19g7969OHToELS1tbk5KLq6utDQ0MCrV68wYsQInD9/HocPH0ZlZSV3jYGBAdTU1KCrq4vJkydj9uzZMDQ0hIGBAebMmQNnZ2eRpVSEEEKIIuFr9RCpnVQjLbXNOdm5cycmTJiA27dvw9bWVuI1J06cgIeHB4DqCbpz587F3r178eLFC/Tp0webNm2CpaVlnR+cRloIIYTUVUOMtDz4/59xsjJNTOQlTlNE2/gTQghp8qjT0jRI9XqIEEIIIZLR6yH5o04LIYQQwgNWVfsOtIQfMu2ISwghhBDSUHjN8vymqVOnQiAQIDw8nCt7/PgxZs6cCXt7e2hqasLKygqBgYFcSgBCCCFEEb2vfVo+JLxmeX5dTEwMUlNTYWFhIVJ+//593L9/H2vWrEFmZiZ27dqF+Ph4TJ48WbaWEEIIIe8RYwJeDlI7XrM817h37x5mzJiBI0eOoH///iL3ODk54cCBA9z3LVu2xPLly/Hpp5/i1atXUFGhaTaEEEIUD42SyB/vWZ6rqqrg7++PuXPnom3btnWOo6OjQx0WQgghhNSq3r2E2rI8r1q1CioqKggMDKxTnMLCQixbtgxTp06t9ZqysjKUlZWJlJWzSqgJlOv38IQQQgjPaPWQ/PGa5Tk9PR3r16/Hrl27at0993XFxcXo378/HB0dsWjRolqvoyzPhBBCGjvG+DlI7eq1I+7MmTMRExODkydPimzbHx4ejpCQECgp/V9fqLKyEkpKSrC0tMTt27e58mfPnsHb2xuampo4fPgw1NXVa61P0kjLZYdxNNJCCCGkThpiR9xctz68xLFK+5uXOE2RVK+H3szy/GaeIX9/f7Gkh97e3vD398fEiRO5suLiYnh7e0MoFCI2NvatHRYAEAqFEAqFImXUYSGEENKY0Osh+eM1y7OhoSEMDQ1F7lFVVYWZmRns7e0BVI+weHl5obS0FHv27EFxcTGKi4sBAMbGxlBWps4IIYQQxUOdFvmTqtOyefNmAOCyNdeoyfJcF+np6UhNTQUA2NnZiZzLycmBjY2NNI9ECCGEkA+E1K+HpPX6PBagusOjoImlCSGEkFrRR5v80cYohBBCCA/o9ZD8UcJEQgghhCgEGmkhhBBCeEB5g+RPLlmer169ikGDBkFXVxfa2tro3LkzcnNzxa5jjMHX1xcCgQAxMTH1bgQhhBDyvlGWZ/njPcvzzZs30a1bN7Rp0waJiYm4ePEiFi5cKHEvlvDw8DrtnEsIIYQ0dlVMwMtBasd7luevv/4a/fr1w+rVq7nrWrRoIRbr4sWLWLt2Lc6dOwdzc/P6PDshhBBCPiC8ZnmuqqrCn3/+idatW8Pb2xsmJibo1KmT2Kuf0tJSjBkzBhs3boSZmZksj0AIIYQ0CowJeDlI7erdaZGU5bmgoAAlJSVYuXIlfHx8cPToUQwdOhTDhg1DUlISd29wcDC6dOmCwYMHy94CQgghpBFgVQJeDlK7eq8eqsnyfPr0aa6sqqp6BtHgwYMRHBwMAGjfvj3OnDmDLVu2oGfPnoiNjcXx48dx4cKFOtclKWFiOauk/EOEEELIB6ReIy0zZ85EbGwsTpw4gebNm3PlRkZGUFFRgaOjo8j1Dg4O3Oqh48eP4+bNm9DT04OKigpUVKr7TcOHDxdLD1AjLCwMurq6IseuZ9n1eXRCCCFELhjj5yC1EzAp9tR/M8tzq1atxK7p0qULWrZsiV9++YUrGzp0KDQ0NLB3717k5+fj0aNHIvc4Oztj/fr1GDhwoFjmaEDySMtlh3E00kIIIaRO3O7GyL2Of1v25yWO480/eYnTFPGa5RkA5s6dCz8/P/To0QO9evVCfHw8/vjjDyQmJgIAzMzMJE6+tbKykthhAQChUAihUChSRh0WQggh5MMi1euhzZs3o6ioCB4eHjA3N+eOqKgo7pqhQ4diy5YtWL16NZydnfHzzz/jwIED6NatG+8PTwghhDQWtE+L/Mkly/OkSZMwadIk3uMSQgghjRUtV5Y/SphICCGEEIVACRMJIYQQHtBLA/mjTgshhBDCA5qPIn/UaSGEEEJ4QHNa5E+qOS1hYWH4+OOPoa2tDRMTEwwZMgRZWVki15SUlGDGjBlo3rw5NDQ04ODggM2bN4vFSk5ORu/evaGlpQU9PT14eHjgxYsXsrWGEEII+QBt2rQJtra2UFdXR8eOHXHq1Km3Xp+UlISOHTtCXV0dLVq0wJYtW8SuOXDgABwdHSEUCuHo6Ijo6GiZ65WVVJ2WpKQkfPHFF0hJSUFCQgJevXoFLy8vPH/+nLsmODgY8fHx2LNnD65evYrg4GDMnDkThw4d4q5JTk6Gj48PvLy8cPbsWZw7dw4zZsyAkhLNCyaEEKKY3teOuFFRUQgKCsLXX3+NCxcuoHv37vD19eV2on9TTk4O+vXrh+7du+PChQv46quvEBgYiAMHDnDXJCcnw8/PD/7+/rh48SL8/f0xatQopKam1rtePki1I+6bHj58CBMTEyQlJaFHjx4AACcnJ/j5+WHhwoXcdR07dkS/fv2wbNkyAEDnzp3Rt29f7vv6SGs+pN73EkII+bA0xI64fH0uSfusnTp1QocOHUTeajg4OGDIkCEICwsTu37evHmIjY3F1atXubJp06bh4sWLSE5OBgD4+fmhuLgYf/31F3eNj48P9PX18dtvv9WrXj7INLRRVFQEADAwMODKunXrhtjYWNy7dw+MMZw4cQLXr1+Ht7c3gOpM0KmpqTAxMUGXLl1gamqKnj17iiReJIQQQj5UZWVlKC4uFjneTGVTo7y8HOnp6fDy8hIp9/LywpkzZyTek5ycLHa9t7c30tLSUFFR8dZramLWp14+1LvTwhhDSEgIunXrBicnJ658w4YNcHR0RPPmzaGmpgYfHx9s2rSJ2xH31q1bAIDFixcjICAA8fHx6NChA/r06YPsbMlJECX9BZazyvo+OiGEEMI7xgS8HJKSBNc2cvHo0SNUVlbC1NRUpNzU1JRLtfOm/Px8ide/evWKyw1Y2zU1MetTLx/qvXpoxowZuHTpktgIyYYNG5CSkoLY2FhYW1vj5MmTmD59OszNzeHp6YmqqioAwNSpUzFx4kQAgKurK/7++2/s2LFD4l9MWFgYlixZIlIWoG2Pz3Xa1PfxCSGEEF7xteQ5NDQUISEhImVv5t97k0AgWjdjTKzsXde/WV6XmNLWK6t6dVpmzpyJ2NhYnDx5Es2bN+fKX7x4ga+++grR0dHo378622W7du2QkZGBNWvWwNPTE+bm5gAAR0dHkZgODg61Tt6R9Bd42WFcfR6dEEIIadQkJQmujZGREZSVlcVGNwoKCsRGQWqYmZlJvF5FRQWGhoZvvaYmZn3q5YNUr4cYY5gxYwYOHjyI48ePi2VlrqioQEVFhdgqIGVlZW6ExcbGBhYWFmJLpa9fvw5ra2uJ9QqFQujo6IgclOWZEEJIY8J4OqShpqaGjh07IiEhQaQ8ISEBXbp0kXiPu7u72PVHjx6Fm5sbVFVV33pNTcz61MsHqUZavvjiC+zduxeHDh2CtrY218PS1dWFhoYGdHR00LNnT8ydOxcaGhqwtrZGUlISdu/ejbVr1wKoHkqaO3cuFi1aBBcXF7Rv3x4RERG4du0a9u/fz38LCSGEkAbwvnbEDQkJgb+/P9zc3ODu7o6tW7ciNzcX06ZNA1D9tuLevXvYvXs3gOqVQhs3bkRISAgCAgKQnJyM7du3c6uCAGDWrFno0aMHVq1ahcGDB+PQoUM4duyYyJSQd9UrD1J1WmqWNXl4eIiU79y5ExMmTAAAREZGIjQ0FOPGjcPjx49hbW2N5cuXizQiKCgIL1++RHBwMB4/fgwXFxckJCSgZcuWsrWGEEII+cD4+fmhsLAQS5cuRV5eHpycnBAXF8e9vcjLyxOZfmFra4u4uDgEBwfjxx9/hIWFBTZs2IDhw4dz13Tp0gWRkZFYsGABFi5ciJYtWyIqKgqdOnWqc73yINM+Le8T7dNCCCGkrhpin5Z/zEbwEqdrPr11qA3lHiKEEEJ4UPW+H+ADQJ0WQgghhAcMlDBR3ijZDyGEEEIUglSdls2bN6Ndu3bcsmN3d3eRvASMMSxevBgWFhbQ0NCAh4cHrly5IhIjPz8f/v7+MDMzg5aWFjp06ECrhgghhCi8KsbPQWonVaelefPmWLlyJdLS0pCWlobevXtj8ODBXMdk9erVWLt2LTZu3Ihz587BzMwMffv2xbNnz7gY/v7+yMrKQmxsLDIzMzFs2DD4+fnhwoUL/LaMEEIIaUBVEPBykNrJvHrIwMAA3333HSZNmgQLCwsEBQVh3rx5AKpzBpmammLVqlWYOnUqAKBZs2bYvHkz/P39uRiGhoZYvXo1Jk+eXOd6afUQIYSQumqI1UPHTUfxEqf3g995idMU1XtOS2VlJSIjI/H8+XO4u7sjJycH+fn5IhkfhUIhevbsKZLxsVu3boiKisLjx49RVVWFyMhIlJWVie39QgghhCgSBgEvB6md1KuHMjMz4e7ujpcvX6JZs2aIjo6Go6Mj1zGRlPHxzp073PdRUVHw8/ODoaEhVFRUoKmpiejo6LduLFdWViaWlrucVdJW/oQQQhoNWvIsf1KPtNjb2yMjIwMpKSn43//+h/Hjx+Pff//lzr8r4+OCBQvw5MkTHDt2DGlpaQgJCcHIkSORmZlZa52S0nTvepYt7aMTQgghRIHJPKfF09MTLVu2xLx589CyZUucP38erq6u3PnBgwdDT08PERERuHnzJuzs7HD58mW0bdtWJIadnR22bNkisQ5JIy2XHcbRSAshhJA6aYg5LUdNR/MSx+tBJC9xmiKZ92lhjKGsrAy2trYwMzMTyfhYXl6OpKQkLuNjaWlpdaVvyQItCWV5JoQQ0thV8XSQ2kk1p+Wrr76Cr68vLC0t8ezZM0RGRiIxMRHx8fEQCAQICgrCihUr0KpVK7Rq1QorVqyApqYmxo4dCwBo06YN7OzsMHXqVKxZswaGhoaIiYlBQkICDh8+LJcGEkIIIQ2BOhzyJ1Wn5cGDB/D390deXh50dXXRrl07xMfHo2/fvgCAL7/8Ei9evMD06dPx5MkTdOrUCUePHoW2tjYAQFVVFXFxcZg/fz4GDhyIkpIS2NnZISIiAv369eO/dYQQQghpMijLMyGEkCavIea0/Gk6hpc4/R/8xkucpogSJhJCCCE8qKItVuSOEiYSQgghRCHQSAshhBDCA8obJH+8ZnlevHgx2rRpAy0tLejr68PT0xOpqakiMcrKyjBz5kwYGRlBS0sLgwYNwt27d/lpDSGEEPKeMJ4OUjteszy3bt0aGzduRGZmJk6fPg0bGxt4eXnh4cOHXIygoCBER0cjMjISp0+fRklJCQYMGIDKykp+W0YIIYSQJoW3LM+SMjQXFxdDV1cXx44dQ58+fVBUVARjY2P88ssv8PPzAwDcv38flpaWiIuLg7e3d53rpdVDhBBC6qohVg8dNBvLS5xh+Xt5idMU8Zbl+U3l5eXYunUrdHV14eLiAgBIT09HRUWFSCZoCwsLODk5iWSCJoQQQhRNlUDAy0Fqx1uW5xqHDx/G6NGjUVpaCnNzcyQkJMDIyAgAkJ+fDzU1Nejr64vENDU1RX5+voxNIYQQQkhTJnWnpSbL89OnT3HgwAGMHz8eSUlJXMelV69eyMjIwKNHj7Bt2zaMGjUKqampMDExqTXmm5mg3yQpYWI5q6T8Q4QQQhoNmkQrf1K/HlJTU4OdnR3c3NwQFhYGFxcXrF+/njuvpaUFOzs7dO7cGdu3b4eKigq2b98OADAzM0N5eTmePHkiErOgoACmpqa11hkWFgZdXV2RY9ezbGkfnRBCCJEbSpgof7xlea7L+Y4dO0JVVVUkE3ReXh4uX77MZYKWJDQ0FEVFRSLHBO1Wsj46IYQQwpsqAT8HqR1vWZ6fP3+O5cuXY9CgQTA3N0dhYSE2bdqEu3fvYuTIkQAAXV1dTJ48GbNnz4ahoSEMDAwwZ84cODs7w9PTs9Z6hUIhhEKhSBm9GiKEEEI+LLxleX758iWuXbuGiIgIPHr0CIaGhvj4449x6tQptG3blouxbt06qKioYNSoUXjx4gX69OmDXbt2QVmZOiGEEEIUF+2IK3+U5ZkQQkiT1xD7tOyx+JSXOJ/e38NLnKaIEiYSQgghRCFQwkRCCCGEBzSJVv6o00IIIYTwgJYryx+9HiKEEEKIQpCq07J582a0a9cOOjo60NHRgbu7O/766y/u/IQJEyAQCESOzp07c+cfP36MmTNnwt7eHpqamrCyskJgYCCKior4axEhhBDyHjCeDlI7qV4PNW/eHCtXroSdnR0AICIiAoMHD8aFCxe4Zc0+Pj7YuXMnd4+amhr39f3793H//n2sWbMGjo6OuHPnDqZNm4b79+9j//79fLSHEEIIeS9oTov8SdVpGThwoMj3y5cvx+bNm5GSksJ1WoRCIczMzCTe7+TkhAMHDnDft2zZEsuXL8enn36KV69eQUWFptgQQgghRLJ6z2mprKxEZGQknj9/Dnd3d648MTERJiYmaN26NQICAlBQUPDWOEVFRdDR0aEOCyGEEIWmCLmHnjx5An9/fy6Pn7+/P54+ffrWexhjWLx4MSwsLKChoQEPDw9cuXKFO1/XqR82NjZiU0jmz58v1fNL3VPIzMyEu7s7Xr58iWbNmiE6OprL8Ozr64uRI0fC2toaOTk5WLhwIXr37o309HSxbfgBoLCwEMuWLcPUqVPfWidleSaEENLYKcLqobFjx+Lu3buIj48HAHz++efw9/fHH3/8Ues9q1evxtq1a7Fr1y60bt0a3377Lfr27YusrCxoa2tLNfVj6dKlCAgI4L5v1qyZVM8v9Y645eXlyM3NxdOnT3HgwAH8/PPPSEpK4jour8vLy4O1tTUiIyMxbNgwkXPFxcXw8vKCvr4+YmNjoaqqWmudixcvxpIlS0TKArTt8blOG2kenRBCyAeqIXbE3WLJz4640/6Tz464V69ehaOjI1JSUtCpUycAQEpKCtzd3XHt2jXY29uL3cMYg4WFBYKCgjBv3jwA1QMJpqamWLVqVa2DDvv27cOnn36K58+fc29SbGxsEBQUhKCgoHq3QerXQ2pqarCzs4ObmxvCwsLg4uKC9evXS7zW3Nwc1tbWyM7OFil/9uwZfHx8uJGat3VYAMryTAgh5MNRVlaG4uJikePNtw31kZycDF1dXa7DAgCdO3eGrq4uzpw5I/GenJwc5Ofnw8vLiysTCoXo2bNnrfcAtU/9WLVqFQwNDdG+fXssX74c5eXlUrVB5n1aGGO1/mEWFhbiv//+g7m5OVdWM8KipqaG2NhYqKurv7MOoVDILbOuOejVECGEkMaErzktYWFh3JyTmiMsLEzm58vPz4eJiYlYuYmJCfLz82u9BwBMTU1Fyk1NTWu9p7apH7NmzUJkZCROnDiBGTNmIDw8HNOnT5eqDVLNafnqq6/g6+sLS0tLPHv2DJGRkUhMTER8fDxKSkqwePFiDB8+HObm5rh9+za++uorGBkZYejQoQCqR1i8vLxQWlqKPXv2cD1IADA2NqZMz4QQQhQWX3NaQkNDERISIlImaV5oDUlTKN507tw5AIBAIL4umzEmsfx1b56v7Z7i4mL0798fjo6OWLRokci54OBg7ut27dpBX18fI0aM4EZf6kKqTsuDBw/g7++PvLw86Orqol27doiPj0ffvn3x4sULZGZmYvfu3Xj69CnMzc3Rq1cvREVFQVtbGwCQnp6O1NRUAOD2eqmRk5MDGxsbaR6HEEIIaXKEQuFbOylvmjFjBkaPHv3Wa2xsbHDp0iU8ePBA7NzDhw/FRlJq1Gxhkp+fL/LWpKCgQOweaad+1Gw+e+PGDfl0WrZv317rOQ0NDRw5cuSt93t4eEDKeb+EEEKIQnhfn25GRkYwMjJ653Xu7u4oKirC2bNn8cknnwAAUlNTUVRUhC5duki8x9bWFmZmZkhISICrqyuA6gU5SUlJWLVqFXddcXExvL29IRQK6zz148KFCwAg0hl6F9ochRBCCOFBY98R18HBAT4+PggICMBPP/0EoHrJ84ABA0RWDrVp0wZhYWEYOnQoBAIBgoKCsGLFCrRq1QqtWrXCihUroKmpibFjxwKo29SP5ORkpKSkoFevXtDV1cW5c+cQHByMQYMGwcrKqs5toE4LIYQQ8oH49ddfERgYyK0GGjRoEDZu3ChyTVZWlsjGcF9++SVevHiB6dOn48mTJ+jUqROOHj0q1dQPoVCIqKgoLFmyBGVlZbC2tkZAQAC+/PJLqZ5f6n1aGou05kPe9yMQQghREA2xT8s6K372aQnOlc8+LU0Br1me39yet+b47rvvxGIxxuDr6wuBQICYmBiZG0IIIYS8T4qwjb+ik6rTUpPlOS0tDWlpaejduzcGDx7M5SDIy8sTOXbs2AGBQIDhw4eLxQoPD3/nEitCCCGEkBq8Znl+M7vzoUOH0KtXL7Ro0UKk/OLFi1i7di3OnTsn1axhQgghpLFSyLkWCqbeE3ErKyuxb98+sSzPNR48eIA///wTERERIuWlpaUYM2YMNm7cKNbJIYQQQhRVY1891BTwmuX5dREREdDW1hZLlBgcHIwuXbpg8ODBda6TsjwTQghp7Gg+ivxJnXvI3t4eGRkZSElJwf/+9z+MHz8e//77r9h1O3bswLhx40Q2mImNjcXx48cRHh4uVZ2S8jDsepb97hsJIYQQ0mTIvOTZ09MTLVu25DaqAYBTp06hR48eyMjIgIuLC1ceFBSEDRs2QEnp//pKlZWVUFJSQvfu3ZGYmCixDkkjLZcdxtFICyGEkDppiCXPYdb8LHkOvUNLnmsj8+ZykrI8b9++HR07dhTpsADA/PnzMWXKFJEyZ2dnrFu3TmyS7+sk5WGgDgshhJDGpIqm4sodb1meaxQXF2Pfvn34/vvvxe43MzOTOPnWysoKtra29Xh8QgghhHwoeMvyXCMyMhKMMYwZM4b3hyWEEEIaK5qIK3+0jT8hhJAmryHmtCy1HsdLnG/u/MpLnKZI6tVDhBBCCCHvA2V5JoQQQnhAr4fkjzothBBCCA9oR1z54zXL84MHDzBhwgRYWFhAU1MTPj4+yM4W3wQuOTkZvXv3hpaWFvT09ODh4YEXL17I3hpCCCGENFm8ZXlmjGHIkCG4desWDh06hAsXLsDa2hqenp54/vw5FyM5ORk+Pj7w8vLC2bNnce7cOcyYMUNkwzlCCCFE0VSB8XKQ2sm8esjAwADfffcdunfvDnt7e1y+fBlt27YFUL3brYmJCVatWsVtKte5c2f07dsXy5Ytk+nBafUQIYSQumqI1UNf24zlJc7y23t5idMU1Xt4o7KyEpGRkVyW55pdcV/PNaSsrAw1NTWcPn0aAFBQUIDU1FSYmJigS5cuMDU1Rc+ePbnzhBBCiKKq4ukgtZO605KZmYlmzZpBKBRi2rRpXJbnNm3awNraGqGhoXjy5AnKy8uxcuVK5OfnIy8vDwBw69YtAMDixYsREBCA+Ph4dOjQAX369JE496VGWVkZiouLRY5yVlnPJhNCCCFEEfGW5VlVVRUHDhzA9evXYWBgAE1NTSQmJsLX1xfKytV5gqqqqvuQU6dOxcSJE+Hq6op169bB3t4eO3bsqLVOyvJMCCGksaM5LfIndadFTU0NdnZ2cHNzQ1hYGFxcXLB+/XoAQMeOHZGRkYGnT58iLy8P8fHxKCws5PIKmZubAwAcHR1FYjo4OCA3N7fWOkNDQ1FUVCRyTNBuJe2jE0IIIXLDeDpI7WResiMpy7Ouri6MjY2RnZ2NtLQ0DB48GABgY2MDCwsLZGVliVx//fp1WFtb11qHUCjkllnXHJTlmRBCCPmw8Jrled++fTA2NoaVlRUyMzMxa9YsDBkyBF5eXgAAgUCAuXPnYtGiRXBxcUH79u0RERGBa9euYf/+/fy3jhBCCGkgNIlW/njN8pyXl4eQkBA8ePAA5ubm+Oyzz7Bw4UKRGEFBQXj58iWCg4Px+PFjuLi4ICEhAS1btuSvVYQQQkgDo/ko8kdZngkhhDR5DbFPS4jNaF7irL0dyUucpohyDxFCCCE8UMgRAAVDnRZCCCGEBzSnRf4o4Q8hhBBCFAKNtBBCCCE8YPSCSO5kGmkJCwuDQCBAUFAQV3bw4EF4e3vDyMgIAoEAGRkZYvfl5+fD398fZmZm0NLSQocOHWjJMyGEEIVGuYfkr96dlnPnzmHr1q1o166dSPnz58/RtWtXrFy5stZ7/f39kZWVhdjYWGRmZmLYsGHw8/PDhQsX6vs4hBBCyHtF2/jLX706LSUlJRg3bhy2bdsGfX19kXP+/v745ptv4OnpWev9ycnJmDlzJj755BO0aNECCxYsgJ6eHs6fP1+fxyGEEELIB6BenZYvvvgC/fv3f2vH5G26deuGqKgoPH78GFVVVYiMjERZWRk8PDzqFY8QQgh53yj3kPxJPRE3MjIS58+fx7lz5+pdaVRUFPz8/GBoaAgVFRVoamoiOjq61l1xy8rKxPIblbNKyj9ECCGk0aBXO/In1UjLf//9h1mzZmHPnj1QV1evd6ULFizAkydPcOzYMaSlpSEkJAQjR45EZmamxOvDwsKgq6srcux6ll3v+gkhhBCieKTqtKSnp6OgoAAdO3aEiooKVFRUkJSUhA0bNkBFRQWVlZXvjHHz5k1s3LgRO3bsQJ8+feDi4oJFixbBzc0NP/74o8R7QkNDUVRUJHJM0G4lzaMTQgghcqUIq4eePHkCf39/bgDA398fT58+fes9jDEsXrwYFhYW0NDQgIeHB65cuSJyjYeHBwQCgcgxerRoWoP61P0mqTotffr0QWZmJjIyMrjDzc0N48aNQ0ZGBpSV3/26prS0tLpiJdGqlZWVUVUl+a9LKBRCR0dH5KBXQ4QQQhoTxtP/5Gns2LHIyMhAfHw84uPjkZGRAX9//7fes3r1aqxduxYbN27EuXPnYGZmhr59++LZs2ci1wUEBCAvL487fvrpJ5nrfpNUc1q0tbXh5OQkUqalpQVDQ0Ou/PHjx8jNzcX9+/cBAFlZWQAAMzMzmJmZoU2bNrCzs8PUqVOxZs0aGBoaIiYmBgkJCTh8+LBUD08IIYSQurl69Sri4+ORkpKCTp06AQC2bdsGd3d3ZGVlwd7eXuwexhjCw8Px9ddfY9iwYQCAiIgImJqaYu/evZg6dSp3raamJszMzHirWxLet/GPjY2Fq6sr+vfvDwAYPXo0XF1dsWXLFgCAqqoq4uLiYGxsjIEDB6Jdu3bYvXs3IiIi0K9fP74fhxBCCGkQfL0eKisrQ3Fxscjx5mKU+khOToauri7XaQCAzp07Q1dXF2fOnJF4T05ODvLz8+Hl5cWVCYVC9OzZU+yeX3/9FUZGRmjbti3mzJkjMhJTn7olkXkb/8TERJHvJ0yYgAkTJrz1nlatWuHAgQOyVk0IIYQ0Gny92gkLC8OSJUtEyhYtWoTFixfLFDc/Px8mJiZi5SYmJsjPz6/1HgAwNTUVKTc1NcWdO3e478eNGwdbW1uYmZnh8uXLCA0NxcWLF5GQkFDvuiWh3EOEEEJIIxIaGoqQkBCRMqFQWOv1ixcvFuvkvKlmmxKBQCB2jjEmsfx1b55/856AgADuaycnJ7Rq1Qpubm44f/48OnToIFPdr6NOCyGEEMIDvlb+CIXCt3ZS3jRjxgyxlTpvsrGxwaVLl/DgwQOxcw8fPhQbSalRM0clPz8f5ubmXHlBQUGt9wBAhw4doKqqiuzsbHTo0AFmZmZS1y0JdVoIIYQQHlSx97O5nJGREYyMjN55nbu7O4qKinD27Fl88sknAIDU1FQUFRWhS5cuEu+peeWTkJAAV1dXAEB5eTmSkpKwatWqWuu6cuUKKioquI5OfeqWhPcsz6+bOnUqBAIBwsPDRcrLysowc+ZMGBkZQUtLC4MGDcLdu3dleRRCCCHkvWrs2/g7ODjAx8cHAQEBSElJQUpKCgICAjBgwACR1Ttt2rRBdHQ0AHCf8StWrEB0dDQuX76MCRMmQFNTE2PHjgVQvf/a0qVLkZaWhtu3byMuLg4jR46Eq6srunbtKlXd78J7lucaMTExSE1NhYWFhdi5oKAgREdHIzIyEqdPn0ZJSQkGDBhQp83pCCGEEFI/v/76K5ydneHl5QUvLy+0a9cOv/zyi8g1WVlZKCoq4r7/8ssvERQUhOnTp8PNzQ337t3D0aNHoa2tDQBQU1PD33//DW9vb9jb2yMwMBBeXl44duyYyP5tdan7XQSMST+eVVJSgg4dOmDTpk349ttv0b59e5HRlHv37qFTp044cuQI+vfvj6CgIG40pqioCMbGxvjll1/g5+cHALh//z4sLS0RFxcHb2/vOj1DWvMh0j42IYSQD5Tb3Ri51zHWeigvcfbeieYlTlPEe5bnqqoq+Pv7Y+7cuWjbtq3Y+fT0dFRUVIis+bawsICTk5NUa7UJIYSQxkQRdsRVdLxneV61ahVUVFQQGBgo8Xx+fj7U1NSgr68vUm5qalrrWm3K8kwIIYQQXrM8p6enY/369di1a5dU666Bt6/VpizPhBBCGjtFSJio6HjN8pyYmIiCggJYWVlx5+/cuYPZs2fDxsYGQPWa7/Lycjx58kQk9tvWfFOWZ0IIIY1dFRgvB6mdVK+HarI8v27ixIlo06YN5s2bB3Nzc7GJtN7e3vD398fEiRMBAB07doSqqioSEhIwatQoAEBeXh4uX76M1atXS6xX0kY79GqIEEII+bDwnuXZ0NBQ5LyqqirMzMy4ddi6urqYPHkyZs+eDUNDQxgYGGDOnDlwdnaWOLGXEEIIUQQ0iVb+3suOuOvWrYOKigpGjRqFFy9eoE+fPti1a5fIem5CCCFEkdB8FPmr1z4tjQHt00IIIaSuGmKflmHWg3iJc/BOLC9xmiLKPUQIIYTwQEHHABQKdVoIIYQQHtDKH/mjTgshhBDCA5rTIn9yyfJ89epVDBo0CLq6utDW1kbnzp2Rm5sLAHj8+DFmzpwJe3t7aGpqwsrKCoGBgSLJmQghhBBC3lTvkZbasjzfvHkT3bp1w+TJk7FkyRLo6uri6tWr3A669+/fx/3797FmzRo4Ojrizp07mDZtGu7fv4/9+/fL1hpCCCHkPaElz/LHe5bn0aNHQ1VVVap00/v27cOnn36K58+fQ0Wlbv0oWj1ECCGkrhpi9VA/q368xInLjeMlTlPEa5bnqqoq/Pnnn2jdujW8vb1hYmKCTp06ISYm5q3xioqKoKOjU+cOCyGEEEI+PFJ3WmqyPIeFhYmdKygoQElJCVauXAkfHx8cPXoUQ4cOxbBhw5CUlCQxXmFhIZYtW4apU6fWWmdZWRmKi4tFjnJWKe2jE0IIIXLDGOPlILXjNctzVVX13OnBgwcjODgY7du3x/z58zFgwABs2bJF7Pri4mL0798fjo6OWLRoUa31UpZnQgghjR1leZY/XrM8GxoaQkVFBY6OjiL3OTg4cKuHajx79gw+Pj5o1qwZoqOjoaqqWmu9lOWZEEIIIbxmeRYKhfj444+RlZUlcs3169dhbW3NfV9cXAxvb28IhULExsZKHLV5HWV5JoQQ0tjR6iH54z3L89y5c+Hn54cePXqgV69eiI+Pxx9//IHExEQA1SMsXl5eKC0txZ49e7g5KgBgbGxMSRMJIYQoJNoRV/54X64zdOhQbNmyBWFhYQgMDIS9vT0OHDiAbt26Aah+xZSamgoAsLOzE7k3JycHNjY2fD8SIYQQQpoAyvJMCCGkyWuIfVr6NPfiJc7fd4/yEqcpoo1RCCGEEB7Q6yH5o04LIYQQwgOaiCt/MiVMJIQQQghpKLxneS4pKcGMGTPQvHlzaGhowMHBAZs3b5Z4P2MMvr6+EAgE79zqnxBCCGnMqhjj5SC14z3Lc3BwME6cOIE9e/bAxsYGR48exfTp02FhYYHBgweLXBseHg6BQFDfRyCEEEIaDepuyF+9RlpKSkowbtw4bNu2Dfr6+iLnkpOTMX78eHh4eMDGxgaff/45XFxckJaWJnLdxYsXsXbtWuzYsaP+T08IIYSQDwavWZ4BoFu3boiNjcW9e/fAGMOJEydw/fp1eHt7c9eUlpZizJgx2LhxI8zMzOr/9IQQQkgjUQXGy0FqJ/XroZosz+fOnZN4fsOGDQgICEDz5s2hoqICJSUl/Pzzz9zmckD1K6QuXbqIvS4ihBBCFBV1OORPqk5LTZbno0eP1povaMOGDUhJSUFsbCysra1x8uRJTJ8+Hebm5vD09ERsbCyOHz+OCxcu1LnesrIylJWViZSVs0rKP0QIIYR8QKTaETcmJgZDhw4VyQ9UWVkJgUAAJSUlFBUVQV9fH9HR0ejfvz93zZQpU3D37l3Ex8cjKCgIGzZsgJKSkkgMJSUldO/enctR9LrFixdjyZIlImUB2vb4XKeNNG0lhBDygWqIHXE7W3jwEiflfiIvcZoiXrM8V1ZWoqKiQqRDAgDKysqoqqoCAMyfPx9TpkwROe/s7Ix169Zh4MCBEusNDQ1FSEiISNllh3HSPDohhBAiV/R6SP54z/Lcs2dPzJ07FxoaGrC2tkZSUhJ2796NtWvXAgDMzMwkTr61srKCra2txHqFQiGEQqFIGb0aIoQQQj4svG/jHxkZidDQUIwbNw6PHz+GtbU1li9fjmnTpvFdFSGEENJo0Db+8idzp+XNOShmZmbYuXOnVDEUNNE0IYQQwqHPMvmj3EOEEEIIDxRhn5YnT57A398furq60NXVhb+/P54+ffrWexhjWLx4MSwsLKChoQEPDw9cuXKFO3/79m0IBAKJx759+7jrbGxsxM7Pnz9fquenTgshhBDygRg7diwyMjIQHx+P+Ph4ZGRkwN/f/633rF69GmvXrsXGjRtx7tw5mJmZoW/fvnj27BkAwNLSEnl5eSLHkiVLoKWlBV9fX5FYS5cuFbluwYIFUj0/73NaCCGEkA8RX6+HJO1NJmlBirSuXr2K+Ph4pKSkoFOnTgCAbdu2wd3dHVlZWbC3txe7hzGG8PBwfP311xg2bBgAICIiAqampti7dy+mTp0KZWVlsQU20dHR8PPzQ7NmzUTKtbW1ZdoJn0ZaCCGEEB7w9XooLCyMe31Tc4SFhcn8fMnJydDV1eU6LADQuXNn6Orq4syZMxLvycnJQX5+Pry8vLgyoVCInj171npPeno6MjIyMHnyZLFzq1atgqGhIdq3b4/ly5ejvLxcqjZI1WlZvHix2Puo13tM73rvVSM5ORm9e/eGlpYW9PT04OHhgRcvXkj14IQQQkhTFBoaiqKiIpEjNDRU5rj5+fkwMTERKzcxMUF+fn6t9wCAqampSLmpqWmt92zfvh0ODg7o0qWLSPmsWbMQGRmJEydOYMaMGQgPD8f06dOlaoPUr4fatm2LY8eOcd+/vjtuzXuvXbt2oXXr1vj222/Rt29fZGVlQVtbG0B1h8XHxwehoaH44YcfoKamhosXL4ptSEcIIYQoEr6WPEv7KkjSrvFvqskXKBAIxM4xxiSWv+7N87Xd8+LFC+zduxcLFy4UOxccHMx93a5dO+jr62PEiBHc6EtdSN1pUVFRkfg+qi7vvWoeOjAwUGTGcKtWraR9DEIIIaRRqXpPS55nzJiB0aNHv/UaGxsbXLp0CQ8ePBA79/DhQ7GRlBo1n/f5+fkwNzfnygsKCiTes3//fpSWluKzzz5753N37twZAHDjxo06d1qkHt7Izs6GhYUFbG1tMXr0aNy6dQtA3d57FRQUIDU1FSYmJujSpQtMTU3Rs2dPnD59WtrHIIQQQggAIyMjtGnT5q2Huro63N3dUVRUhLNnz3L3pqamoqioSOxVTg1bW1uYmZkhISGBKysvL0dSUpLEe7Zv345BgwbB2Nj4nc9dkzj59c7Qu0jVaenUqRN2796NI0eOYNu2bcjPz0eXLl1QWFhYp/deNR2cxYsXIyAgAPHx8ejQoQP69OmD7OzsWustKytDcXGxyFHOKqV5dEIIIUSuGE//kxcHBwf4+PggICAAKSkpSElJQUBAAAYMGCCycqhNmzaIjo4GUP1aKCgoCCtWrEB0dDQuX76MCRMmQFNTE2PHjhWJf+PGDZw8eVIsvyBQPTVk3bp1yMjIQE5ODn7//XdMnToVgwYNgpWVVZ3bINXrodfXWzs7O8Pd3R0tW7ZEREQEN8zztvdeNUkTp06diokTJwIAXF1d8ffff2PHjh21zo4OCwujLM+EEEIatff1ekgav/76KwIDA7m3IoMGDcLGjRtFrsnKykJRURH3/ZdffokXL15g+vTpePLkCTp16oSjR49yc1Vr7NixAx999JHIG5caQqEQUVFRWLJkCcrKymBtbY2AgAB8+eWXUj2/gMm4sLxv376ws7PD3Llz0bJlS5w/fx6urq7c+cGDB0NPTw8RERHIyclBixYt8Msvv+DTTz/lrvHz84OKigp+/fVXiXVIWrN+2WEcJU0khBBSJ253Y+Reh4PJJ7zEuVpw9t0XfaBkWrJTVlaGq1evwtzcvE7vvWxsbGBhYYGsrCyRONevX4e1tXWt9QiFQujo6Igc1GEhhBDSmDT210NNgVSvh+bMmYOBAwfCysoKBQUF+Pbbb1FcXIzx48eLvPdq1aoVWrVqhRUrVoi89xIIBJg7dy4WLVoEFxcXtG/fHhEREbh27Rr2798vlwYSQgghDUERXg8pOqk6LXfv3sWYMWPw6NEjGBsbo3PnzkhJSeFGSery3isoKAgvX75EcHAwHj9+DBcXFyQkJKBly5b8towQQghpQDRKIn8yz2l5X9KaD3nfj0AIIURBNMScllbGHXmJk/0wnZc4TRElTCSEEEJ4QK+H5I86LYQQQggP6PWQ/FHCH0IIIYQoBN6yPFdUVGDevHlwdnaGlpYWLCws8Nlnn+H+/fsiMfLz8+Hv7w8zMzNoaWmhQ4cOtHKIEEKIwmOsipeD1E7qkZa2bdsiLy+POzIzMwEApaWlOH/+PBYuXIjz58/j4MGDuH79OgYNGiRyv7+/P7KyshAbG4vMzEwMGzYMfn5+XA4CQgghRBFVgfFykNrxluVZV1dXZGM5APjhhx/wySefIDc3l8stkJycjM2bN+OTT6p3DlywYAHWrVsntpMuIYQQQsjreMvyLElRUREEAgH09PS4sm7duiEqKgqPHz9GVVUVIiMjUVZWBg8Pj/o8PyGEENIoMMZ4OUjtpBppqcny3Lp1azx48ADffvstunTpgitXrsDQ0FDk2pcvX2L+/PkYO3YsdHR0uPKoqCj4+fnB0NAQKioq0NTURHR09Fs3l5OUe6icVdJW/oQQQhoNerUjf1KNtPj6+mL48OFwdnaGp6cn/vzzTwBARESEyHUVFRUYPXo0qqqqsGnTJpFzCxYswJMnT3Ds2DGkpaUhJCQEI0eO5ObGSBIWFgZdXV2RY9ezbGkenRBCCCEKjrcsz5s3bwZQ3WEZNWoUbt26hePHj4uMwNy8eRN2dna4fPky2rZty5V7enrCzs4OW7ZskVgHZXkmhBAii4bYEfcj/bbvvqgO7j25wkucpkimzeVqsjx3794dwP91WLKzs3HixAmxV0alpaUAACUl0QEeZWVlVFXVvsxLKBRCKBSKlFGHhRBCSGNCO+LKH29Znl+9eoURI0bg/PnzOHz4MCorK5Gfnw8AMDAwgJqaGtq0aQM7OztMnToVa9asgaGhIWJiYpCQkIDDhw/LpYGEEEJIQ6AdceWPtyzPt2/fRmxsLACgffv2IvedOHECHh4eUFVVRVxcHObPn4+BAweipKQEdnZ2iIiIQL9+/XhrFCGEEEKaHsryTAghpMlriDktprpteInzoOgaL3GaIkqYSAghhPCAljzLHyVMJIQQQohCoJEWQgghhAcKOttCofCW5RkAJkyYIHa+c+fOIjHKysowc+ZMGBkZQUtLC4MGDcLdu3f5aQ0hhBDynlQxxstBasdblucaPj4+Iufj4uJEzgcFBSE6OhqRkZE4ffo0SkpKMGDAAFRWVsrWEkIIIYQ0abxlea4hFAprPV9UVITt27fjl19+gaenJwBgz549sLS0xLFjx+Dt7S3t4xBCCCGNAr0ekj/eszwnJibCxMQErVu3RkBAAAoKCrhz6enpqKiogJeXF1dmYWEBJycnnDlzRoZmEEIIIe9XFRgvB6mdVJ2WmizPR44cwbZt25Cfn48uXbqgsLAQQHVCxV9//RXHjx/H999/j3PnzqF3795c3qD8/HyoqalBX19fJK6pqSm3ey4hhBBCiCRSvR7y9fXlvnZ2doa7uztatmyJiIgIhISEwM/Pjzvv5OQENzc3WFtb488//8SwYcNqjcsYg0AgqPW8pISJ5ayS8g8RQghpNOj1kPzJtE+LlpYWnJ2dkZ2dLfG8ubk5rK2tufNmZmYoLy/HkydPRK4rKCiAqalprfWEhYVBV1dX5Nj1THKdhBBCyPtAq4fkT6ZOS02WZ3Nzc4nnCwsL8d9//3HnO3bsCFVVVSQkJHDX5OXl4fLly+jSpUut9YSGhqKoqEjkmKDdSpZHJ4QQQnjFePofqR1vWZ5LSkqwePFiDB8+HObm5rh9+za++uorGBkZYejQoQAAXV1dTJ48GbNnz4ahoSEMDAwwZ84cODs7c6uJJBEKhRAKhSJl9GqIEEII+bDwluX5xYsXyMzMxO7du/H06VOYm5ujV69eiIqKgra2Nhdj3bp1UFFRwahRo/DixQv06dMHu3btgrIydUIIIYQoLnq1I3+U5ZkQQkiT1xBZntXVrXiJ8/JlLi9xmiJKmEgIIYQQhUAJEwkhhBAe0CRa+aNOCyGEEMIDBZ1toVDo9RAhhBDygXjy5An8/f25Pc/8/f3x9OnTt95z8OBBeHt7w8jICAKBABkZGWLXlJWVYebMmTAyMoKWlhYGDRqEu3fvylz3m6jTQgghhPCAMcbLIU9jx45FRkYG4uPjER8fj4yMDPj7+7/1nufPn6Nr165YuXJlrdcEBQUhOjoakZGROH36NEpKSjBgwABUVlbKVPebaPUQIYSQJq8hVg+pqH3ES5xX5fd4ifOmq1evwtHRESkpKejUqRMAICUlBe7u7rh27Rrs7e3fev/t27dha2uLCxcuoH379lx5UVERjI2N8csvv3DpfO7fvw9LS0vExcXB29tb5rpr0EgLIYQQ0oiUlZWhuLhY5Hgz/159JCcnQ1dXl+s0AEDnzp2hq6uLM2fO1Dtueno6Kioq4OXlxZVZWFjAycmJi8tb3ayJefnyJVu0aBF7+fKlQsanOhpXHU2hDVRH44lPdTS+OhqjRYsWMQAix6JFi2SOu3z5ctaqVSux8latWrEVK1a88/6cnBwGgF24cEGk/Ndff2Vqampi1/ft25d9/vnnvNRdo8l1WoqKihgAVlRUpJDxqY7GVUdTaAPV0XjiUx2Nr47G6OXLl6yoqEjkeFvHTVIn583j3LlzbPny5ax169Zi99vZ2bGwsLB3Ppe0nRZPT082depUxhiTue4atOSZEEIIaUQk5dt7mxkzZmD06NFvvcbGxgaXLl3CgwcPxM49fPgQpqamUj9nDTMzM5SXl+PJkyfQ19fnygsKCrhkyGZmZrzUTZ0WQgghRIEZGRnByMjonde5u7ujqKgIZ8+exSeffAIASE1NRVFREde5qI+OHTtCVVUVCQkJGDVqFAAgLy8Ply9fxurVq3mtmzothBBCyAfAwcEBPj4+CAgIwE8//QQA+PzzzzFgwACR1Ttt2rRBWFgYhg4dCgB4/PgxcnNzcf/+fQBAVlYWgOrREzMzM+jq6mLy5MmYPXs2DA0NYWBggDlz5sDZ2Rmenp5S1f0uTW71kFAoxKJFi6QaWmtM8amOxlVHU2gD1dF44lMdja+OD82vv/4KZ2dneHl5wcvLC+3atcMvv/wick1WVhaKioq472NjY+Hq6or+/fsDAEaPHg1XV1ds2bKFu2bdunUYMmQIRo0aha5du0JTUxN//PEHlJWVpar7XRR2nxZCCCGEfFia3EgLIYQQQpom6rQQQgghRCFQp4UQQgghCoE6LYQQQghRCNRpIYQQQohCoE4L4V1VVRWuX7+O06dP4+TJkyIHaXg3btzAkSNH8OLFCwCAIi4YbAptkLeTJ0/i1atXYuWvXr3i7b+9Fi1aoLCwUKz86dOnaNGihczxG6INRLHRkmcpVFVV4caNGygoKEBVVZXIuR49erynp5LO33//jb///ltiG3bs2CFz/JSUFIwdOxZ37twR+2ARCASorKyUuQ55t6Gh3Lx5Ezt37sTNmzexfv16mJiYID4+HpaWlmjbtq3M8QsLC+Hn54fjx49DIBAgOzsbLVq0wOTJk6Gnp4fvv/+eh1YAv/zyC7Zs2YKcnBwkJyfD2toa4eHhsLW1xeDBgxWiDS1atMC5c+dgaGgoUv706VN06NABt27dkin+pEmTsH79emhra4uUP3/+HDNnzuTl362ysjLy8vJgYmIiUl5YWAgTExNe/ttTUlJCfn6+WB0PHjyAlZWVzJmIG6INRLEp7I64GzZsqPO1gYGBMtcn7w/jBw8eYM6cOdyH8Zt18PEf65IlS7B06VK4ubnB3NwcAoFA5phvmjZtGtzc3PDnn3/KpY6GaEMNeX4YJyUlwdfXF127dsXJkyexfPlymJiY4NKlS/j555+xf/9+mZ8/ODgYKioqyM3NhYODA1fu5+eH4OBgXj7wN2/ejG+++QZBQUFYvnw59+9UT08P4eHhMv85NUQbAOD27dsS/xsrKyvDvXv3ZI4fERGBlStXinVaXrx4gd27d/PSaWGMSfzvobCwEFpaWjLFjo2N5b4+cuQIdHV1ue8rKyvx999/w8bGRqY6APm2gTQNCttpWbduncj3Dx8+RGlpKfT09ABU/4akqakJExMTXjot8v4wnjBhAnJzc7Fw4UK5fRhv2bIFu3btgr+/P++xa2RnZ2P//v2ws7OTS/yGaAMg/w/j+fPn49tvv0VISIjIB1mvXr2wfv16mWLXOHr0KI4cOYLmzZuLlLdq1Qp37tzhpY4ffvgB27Ztw5AhQ7By5Uqu3M3NDXPmzJE5vrzbIO8P4+LiYjDGwBjDs2fPoK6uLhI/Li5ObFRBWsOGDQNQ/cvThAkTRHaPraysxKVLl2TKKwMAQ4YM4eoYP368yDlVVVXY2NjI1IFsiDaQpkFhOy05OTnc13v37sWmTZuwfft2LodBVlYWAgICMHXqVF7qk/eH8enTp3Hq1Cm0b99eLvEBoLy8XO7/4Xfq1Ak3btyQ259TQ7QBkP+HcWZmJvbu3StWbmxsLHHOQH08f/4cmpqaYuWPHj3ibVv0nJwcuLq6ipULhUI8f/5c5vjyboO8P4z19PQgEAggEAjQunVrsfMCgQBLliypd3wAXEeLMQZtbW1oaGhw59TU1NC5c2cEBATIVEfNa1hbW1ucO3euTsn5pNEQbSBNg8J2Wl63cOFC7N+/XyTpkr29PdatW4cRI0Zg3LhxMtch7w9jS0tLuU8unDJlCvbu3YuFCxfKrY6ZM2di9uzZyM/Ph7OzM1RVVUXOt2vXTqb4DdEGQP4fxnp6esjLy4Otra1I+YULF/DRRx/JHB+onme1e/duLFu2DED1B2RVVRW+++479OrVi5c6bG1tkZGRAWtra5Hyv/76C46OjjLHl3cb5P1hfOLECTDG0Lt3bxw4cAAGBgbcOTU1NVhbW8PCwkKmOnbu3AkAsLGxwZw5c+T6GuX1XxZrPH36lBvhrq+GbANRbE2i05KXl4eKigqx8srKSjx48ICXOuT9YRweHo758+fjp59+4uXdsCQvX77E1q1bcezYMbRr106sDWvXrpW5juHDhwOonnhYQyAQcO+qZZ2b0xBtAOT/YTx27FjMmzcP+/bt4z6I//nnH8yZMwefffaZzPEB4LvvvoOHhwfS0tJQXl6OL7/8EleuXMHjx4/xzz//8FLH3Llz8cUXX+Dly5dgjOHs2bP47bffEBYWhp9//lnm+A3RBkB+H8Y9e/bk4ltZWcl1DtaXX34p8ovPnTt3EB0dDUdHR3h5efFSx6pVq2BjYwM/Pz8AwMiRI3HgwAGYm5sjLi4OLi4uMsVviDYQBceagAEDBrB27dqxc+fOsaqqKsYYY+fOnWPt27dnAwcO5KUOgUAgdigpKXH/Lys9PT2mpqbGlJSUWLNmzZi+vr7IwQcPD49aj169evFSx+3bt996yKoh2sAYYzt27GAfffQRi4yMZFpaWuy3335j3377Lfe1rMrLy9nYsWO5f0OqqqpMSUmJffrpp+zVq1c8tKBaXl4e++abb1j//v2Zr68v+/rrr9n9+/d5i88YY1u3bmVWVlbcfxfNmzdnP//8M2/xG6INK1euZJGRkdz3I0aMYAKBgFlYWLCMjAyZ4//111/s1KlT3PcbN25kLi4ubMyYMezx48cyx2eMsb59+7LNmzczxhh78uQJMzExYc2bN2fq6ups06ZNvNRha2vL/vnnH8YYY0ePHmV6enrsyJEjbPLkyaxv374yx2+INhDF1iQ6LQUFBczX15cJBAKmpqbG1NTUmEAgYL6+viw/P5+XOuT9Ybxr1663HqThyfvDmDHGbt68yfbt28eioqLY9evXeY3d0B4+fMgePHjwvh+jXuT9Yezk5MT+/PNPxhhjly5dYmpqaiw0NJR16tSJTZgwQeb4jDFmaGjILl++zBhjbNu2baxdu3assrKS/f7776xNmza81KGurs5yc3MZY4wFBgayzz//nDHGWFZWFtPT05M5fkO0gSi2JvF6yNjYGHFxccjOzsbVq1fBGIODg4PEiW/19eZrAr69OQlQ0f3777/Izc1FeXm5SPmgQYPe0xNJLyAgAAEBAXj06BGqqqpkXuUhSYsWLdCiRQtUVlYiMzMTT548gb6+Pi+x4+Pj0axZM3Tr1g0A8OOPP2Lbtm1wdHTEjz/+yEs9L168AGMMmpqaMDIywp07dxAeHs7bcH5DtAGofsVsaWkJADh8+DBGjRoFLy8v2NjYoFOnTjLHz8nJ4V4rHjhwAAMHDsSKFStw/vx59OvXT+b4AFBaWsqtRDt69CiGDRsGJSUldO7cmbfVYvr6+vjvv/9gaWmJ+Ph4fPvttwCqJ9DysS1DQ7SBKDaF7bSEhIRg2bJl0NLSQkhIiNj5pKQk7mu+5jkADfNh/OLFC7E5Ojo6OrzEPnfuHPbt2yexDQcPHpQ5/q1btzB06FBkZmZyc1kAcO/y+fjBJu82APL/MA4KCoKzszMmT56MyspK9OzZE2fOnIGmpiYOHz4MDw8PmeuYO3cuVq1aBaB6tVJISAhmz56N48ePIyQkhJv8KIvBgwdj2LBhmDZtGp4+fYpPPvkEampqePToEdauXYv//e9/jb4NgPw/jNXU1FBaWgoAOHbsGDdvycDAAMXFxTLHBwA7OzvExMRg6NChOHLkCIKDgwEABQUFvP38GDZsGMaOHYtWrVqhsLAQvr6+AICMjAxeFik0RBuIgnufwzyy8PDwYE+ePOG+lvc8h5s3b7J27dqJzGWp+ZqPOS0lJSXsiy++YMbGxlzM1w8+/Pbbb0xVVZX179+fqampsQEDBjB7e3umq6vL2xD1gAED2ODBg1lBQQFr1qwZ+/fff9mpU6fYJ598wk6ePClz/IZoA2Pyf7f+0UcfsXPnzjHGGIuOjmbm5uYsKyuLff3116xLly4yx2eMMS0tLZaTk8MYY2zRokVs+PDhjDHG0tPTmampKS91yHs4vyHawBhjX3zxBbO2tmaenp7M0NCQPXv2jDHGWGRkJHN1dZU5/oABA5i3tzdbunQpU1VVZXfv3mWMMXbkyBHWqlUrmeMzxti+ffu4uVGvv9JasWIF8/Hx4aWO8vJytmbNGhYYGMjOnz/Pla9bt45t27ZN5vgN0Qai2BS209LQ5P1hPH36dObg4MD27dvHNDQ02I4dO9iyZctY8+bN2Z49e3hoAWPOzs5s48aNjDHGmjVrxm7evMmqqqpYQEAA++abb3ipw9DQkF28eJExxpiOjg67du0aY4yxv//+m7Vv317m+A3RBsbk/2EsFArZf//9xxhjLCAggM2aNYsxxtitW7eYtra2zPEZY0xfX59duXKFMcZY165d2U8//cQYYywnJ4dpaGjwUoeGhga7c+cOY4yxkSNHssWLFzPGGMvNzeWljoZoA2Py/zC+c+cOt2Dg9XlRQUFBbObMmTLHr5GXl8fOnz/PKisrubLU1FR29epVmWOXl5ezCRMmsJs3b8oc623k2Qai+KjTUkfy/jC2tLRkJ06cYIwxpq2tzbKzsxljjO3evZv5+vrKHJ8xxjQ1NbnfWg0NDdmlS5cYY4z9+++/zMzMjJc69PT0uB9qLVq0YMePH2eMMXbjxg1ePmQaog2Myf/D2MrKih05coS9evWKWVpasj/++IMxxtjly5d5mdDIGGMDBw6U+2/3zs7ObP369Sw3N5fp6OiwM2fOMMYYS0tL42UkpCHaIO8P44qKCrZr1y7eVzy9WYeysjLLzMyUWx2MMaarqyvXP6eGaANRbJTluY4qKyvRrFkzAICRkRHu378PoHqCblZWlszxHz9+zG00pqOjg8ePHwMAunXrxlt2UwMDAzx79gwA8NFHH+Hy5csAqvejqHnfLisnJydcunQJQPWGfKtXr8Y///yDpUuX8pIFtiHaAPzfu/X//vsPR44c4eax8PVufeLEiRg1ahScnJwgEAjQt29fAEBqairatGkjc3wA2LhxI1RUVLB//35s3ryZ27Tur7/+go+PDy91fPPNN5gzZw43YdXd3R1A9SRKSZvzSash2qCqqoro6GheYkmioqKC//3vf2Lzr/iuw9raWu4JBYcOHYqYmBi5xG6oNhAF9757TYqiW7duLDo6mjHG2JgxY5iPjw87ffo0++yzz1jbtm1lju/s7MwSExMZY9XzKWbPns0YY2z9+vXso48+kjk+Y9XP/f333zPGGPv222+ZsbExmzJlCrO2tmZDhw7lpY74+Hh24MABxlj1PCAHBwcmEAiYkZER+/vvv2WO3xBtYKxh3q3v27ePrV27lntNxFj10veYmBhe4tdVWFgYNz+sPuoynP/ff/+JnOebrG2YMGEC9+9KHjw8PLifH/KyY8cO5uvrywoLC+VWx7fffsv09PTY8OHD2YoVK9j69etFDlk1RBuIYhMwJue945uII0eO4Pnz5xg2bBhu3bqFAQMG4Nq1azA0NERUVBR69+4tU/x169ZBWVkZgYGBOHHiBPr374/Kykq8evUKa9euxaxZs2Ruw+PHj/Hy5UtYWFigqqoKa9aswenTp2FnZ4eFCxfytnxUUr36+vq87AbakG3Iz89HXl4eXFxcoKRUPSh59uxZ6OjocKMhd+/ehYWFBXeeb87OzoiLi+OW48qDjo4OMjIyeBkJe191yBp/+fLlWLNmDfr06YOOHTuKbSMva9LVffv2Yf78+QgODpYYX9YdtQHA1dUVN27cQEVFBaytrcXqOH/+vMx1vJl24nUCgQC3bt2SKX5DtIEoNuq0yIDPD+M35ebmIi0tDS1btpR5a+z34caNG7h58yZ69OgBDQ2NWlPOKzp5fxhra2vj4sWLcu1QNIU6ZI0v7w9jSZ1aPtNbAHhn4sVFixbJXIe8NYU2EPlS2H1a3pfXP4wNDAzkkuTw5cuXsLKygpWVFe+xb968iZ07d+LmzZtYv349TExMEB8fD0tLS7Rt21bm+IWFhRg1ahROnDgBgUCA7OxstGjRAlOmTIGenp5MGXMbqg3SoD5/0yAp95AixQca/gOdvbEHEx+oU0LehSbi1lFhYSH69OmD1q1bo1+/fsjLywNQnXV49uzZMsevrKzEsmXL8NFHH6FZs2bcb3YLFy7E9u3bZY4PVG+45+zsjNTUVBw8eBAlJSUAgEuXLvH2wyI4OBiqqqrIzc2FpqYmV+7n54f4+HiZ4zdEG8iHjVWvquQ1prW19VsPPqWnp2PPnj349ddfceHCBV5jA8Du3bvh7OwMDQ0NaGhooF27dvjll194rUPebSAK7D3NpVE4/v7+zNvbm/3333/c/iCMVS+9dHR0lDn+kiVLWIsWLdiePXuYhoYGFz8qKop17txZ5viMMda5c2dusuHrbTh79iyzsLDgpQ5TU1Muwdzrddy6dYtpaWnJHL8h2iCN159BEeM3lTr4iB8REcGcnJyYUChkQqGQOTs7s927d/P0hNXL/mfMmMH69OnDPD092cyZM9mNGzd4i//gwQPWq1cvJhAImL6+PtPT02MCgYD17t2bFRQU8FLH999/zzQ1NdmXX37JDh06xGJiYtjcuXOZpqYmW7t2rczxG6INRLHRSEsdHT16FKtWrULz5s1Fylu1asVLTozdu3dj69atGDduHJSVlbnydu3a4dq1azLHB6q3QR86dKhYubGxMQoLC3mp4/nz5yIjLDUePXoEoVAoc/yGaAPhX2Ofz1STcqBfv374/fffERUVBR8fH0ybNg3r1q2TOf6RI0fg6OiIs2fPol27dnByckJqairatm2LhIQEHloAzJw5E8XFxbhy5QoeP36MJ0+e4PLlyyguLpZ5InGNH374AZs3b8aqVaswaNAgDB48GKtXr8amTZuwYcMGmeM3RBuIgnvfvSZF0axZMy4L75u/4RsYGMgcX11dncsW/Xr8K1eu8DJCwVj11vE1mWxfr+PgwYOsRYsWvNTRr18/tmDBAq6OW7duscrKSjZy5EhuC3ZZNEQbpKGtrd3oRxDexdfXV64bnzEm/3bI2gYbGxsWEREhVr5r1y5mY2Mjy6Mxxhhr3749mzdvnlj5vHnzeEkTwFj1ppdnz54VK09NTWW6urq81CEUCrmNL193/fp1JhQKZY7fEG0gio1GWuqoR48e2L17N/e9QCBAVVUVvvvuO/Tq1Uvm+G3btsWpU6fEyvft28fLJl0AMHbsWMybNw/5+fnc8//zzz+YM2cOl8BNVt999x1++ukn+Pr6ory8HF9++SWcnJxw8uRJLvGdLBqiDdJg9Zj7UFFRgV69euH69evvvPann36CqalpfR4N58+fR2ZmJvf9oUOHMGTIEHz11VciG53FxcXB3Ny8XnXs2rWrTpv6/fvvv/Wau+Hh4YHdu3fjxYsXb71OljYA1Vmeu3TpIlbepUsXbv6aLK5evYrJkyeLlU+aNAn//vuvzPEBoKqqCqqqqmLlqqqqqKqq4qUOOzs7/P7772LlUVFRaNWqlczxG6INRMG9716Torhy5QozNjZmPj4+TE1NjY0YMYI5ODgwU1NTXt5Lx8bGMl1dXbZy5UqmqanJvvvuOzZlyhSmpqbGjh49ykMLqrcrHzt2LJfwsWbztE8//ZS9evWKlzoYq95s7JtvvmH9+/dnvr6+7Ouvv+btN/mGasObioqKWHR0NPv3339FynNzc+tVr5GRETdyJy9ubm5s//79jLHqjf7U1dXZmDFjmJ2dHZfrSFZmZmZMW1ubTZo0iRsB41NISAgzNTVlOjo6bMqUKSw5OZn3OhhjrG3btmz58uVi5cuWLWNOTk4yx2/evDn7/fffxcqjoqKYpaWlzPEZY2zQoEGsR48e7N69e1zZ3bt3Wc+ePdmQIUN4qWP//v1MWVmZS62wbNky5u3tzVRUVNjBgwdljt8QbSCKjTotUpDnhzFj1bvJ9ujRg2lpaTENDQ3WtWtXduTIEd7i17hx4wbbt28fi4qKkvsHp7zIuw0jR45kP/zwA2OMsdLSUtaqVSumqqrKVFRUuI6ALEJCQiS+LuCTjo4O16FeuXIl8/LyYowxdvr0ada8eXNe6nj16hU7dOgQGzp0KFNTU2P29vZs5cqVLC8vj5f4NXXExMSwwYMHM1VVVebg4MC+++47lp+fz1sd8v4wXrJkCdPT02MrV65kJ0+eZKdOnWJhYWFMT0+PLVu2jIcWVHegXV1dmaqqKmvRogVr2bIlU1VVZR06dBDZdVlWaWlpbNy4caxDhw7M1dWVjRs3TiTJpCwaqg1EcdHmcoR3L1++xKVLl1BQUCA2pDto0KD39FTSMTMzw5EjR+Di4oK9e/di0aJFuHjxIiIiIrB161aZl2HOnDkTu3fvhp2dHdzc3MR2/ly7dq1M8YHqje/S09PRqlUr9O3bFwMGDMCsWbOQm5sLe3v7d75ykVZBQQH27NmDXbt24dq1a/Dx8cHkyZMxcOBA3nYMfvjwIX766ScsX74clZWV6NevHwIDA2XekRqoXma7bt06XL16FYwxODo6Yvbs2by8nmWMITw8HN9//z2Xt8zCwgJz585FYGAgrxOVExIScO3aNa4Nnp6evMVuKE2hDUQ+qNMihYb6MC4pKRGLz0eSPsYY9u/fjxMnTkhsw8GDB2WuIz4+Hp999hkePXokdo6PnT8bog0AoKGhgevXr8PS0hKfffYZLCwssHLlSuTm5sLR0ZHbH6a+3jYPSiAQ4Pjx4zLFB4DevXvD0tISnp6emDx5Mv7991/Y2dkhKSkJ48ePx+3bt2Wu402pqanYsWMHIiIiYG5ujqdPn0JPTw87d+6Eh4eHTLHPnj2LnTt34rfffoOuri4mTJiAvLw8/Prrr/jf//6HNWvW8NMIOatJ+Kmtrc1r3NLSUokr9/g0btw4eHh4wMPDg5c5LG9qiDYQxUY74taRvD+Mc3JyMGPGDCQmJuLly5dcOeNxm+9Zs2Zh69at6NWrF0xNTeWyDHXGjBkYOXIkvvnmm3pPIH2bhmgDAFhaWiI5ORkGBgaIj49HZGQkAODJkydQV1eXOf6JEydkjvEu4eHhGDduHGJiYvD111/Dzs4OALB//36Jk07r68GDB/jll1+wc+dO3Lp1C0OGDMHhw4fh6emJFy9eYMGCBRg/fny9tgYoKCjgYmdnZ2PgwIGIjIyEt7c393c/atQoDBkyRKZOi7w/jLdt28bF5ruzUkNPTw9ubm5cO7p27So2gierZs2a4fvvv8fUqVNhZmaGnj17omfPnvDw8OAlO3lDtIEouPf0WkrhtGzZkk2fPp3X9+ivc3d3Z+7u7iwyMpKdOHGCJSYmihx80NfXZ3/++ScvsWqjra3N64ZZb2qINjDG2I8//shUVFSYnp4ec3Fx4TIUb9iwgXl4ePBWT3Z2NouPj2elpaWMMcaqqqp4i12bFy9esPLycl5iDRgwgKmqqrK2bduydevWSczOe+/ePSYQCOoVX1VVlbVp04atXr261s3FioqKZP47+fzzz5m9vT0TCATM3NycjR49mm3evFkkU7Us3oy9ZcsW3mLXOHPmDAsLC2Pe3t5MW1ubqaqqsk6dOrF58+axuLg4XuvKy8tjv/32G5s6dSpr06YNU1JSYmZmZjLHbcg2EMVEnZY6kveHsZaWFrt27Zrc4jNWvRcF3z8o3zRx4kT2888/yy1+Q7Shxrlz59jBgwfZs2fPuLLDhw+z06dPyxz70aNHrHfv3kwgEDAlJSVuD5NJkyaxkJAQmeMzVj2p8fXJi6mpqWzWrFnsp59+4iU+Y9XPe+bMmbdeU1VVxe1BJI2qqiqWlJTEnj9/Xt/Hk5q8PoxrYu/du5dNnTqV2dvbMyUlJWZqasr8/Px4if+6V69eseTkZDZ+/HimoqLClJSUeI1fUlLC4uPj2fz581nnzp2Zmpoaa9++Pa91yLsNRDFRp6WO5P1h7OHhwRISEuQWn7HqjbJGjx7N/VYvD8+fP2f9+vVj48ePZ2vWrGHr168XOWTVEG1oCPJOC8EYY926deO2oc/Ly2M6OjrM3d2dGRoasiVLlvBSR0REBHv58qVYeVlZmcTN2qRRWVnJVFVVG3SFW0N8GNfUMWHCBKaiosKUlZV5i3316lW2efNmNnr0aGZmZsYMDQ3Z0KFDWXh4OC/xv/zyS9apUyemrq7O3NzcWEhICDt06BB78uQJL/EZk38biGKjibh1VFpaipEjR8LY2BjOzs5iGyDJusX0zZs3MW3aNHz66adwcnISi9+uXTuZ4gPVbRg2bBj++ecf2NjYiNVx/vx5mev4+eefMW3aNGhoaMDQ0FBkzolAIOASQdZXQ7QBqN7062127NghU/zXVydpa2vj4sWLaNGiBXJycuDs7CzzRF8A0NfXR0pKCuzt7bFhwwZERUXhn3/+wdGjRzFt2jSZ/y4AQFlZGXl5eTAxMREpLywshImJicxzsdq2bYvt27ejc+fOMsV5l3nz5iEpKQkXL16Ek5MTevTogZ49e6JHjx7Q09OTOf5ff/2FpKQkJCYm4uLFi2jbti169OgBDw8PdO/eHfr6+jLXYWZmhoqKCvTu3RseHh7o0aMHnJ2dZY77OiUlJRgbGyM4OBiDBw+Gg4MDr/Ebog1EsdFE3Drau3cvjhw5Ag0NDSQmJop9GMvaaXn48CFu3ryJiRMnisRlPE7EnTBhAtLT0/Hpp5/KbRLrggULsHTpUsyfP5+3Za6va4g2ANUTbl9XUVGBy5cv4+nTp7wsr5V3jiag+plrYh07doxb4damTRtednkF/m+i+Jvu3r0LXV1dmeOvXr0ac+fOxebNm+Hk5CRzvNp89913MDY2xqJFi+TyYdy/f38YGxtj9uzZOHLkCC9/Nm8yMzPD1atXkZubi9zcXNy9exe2trZo1qwZb3VcuHCB63x9//33UFZW5ibienh4yPzn1hBtIIqNRlrqyMzMDIGBgXL7MHZ0dISDgwO+/PJLiR/GfKSv19LSwpEjR9CtWzeZY9XGwMAA586dQ8uWLeUSvyHaUJuqqipMnz4dLVq0wJdffilTrP79+6NDhw5YtmwZtLW1cenSJVhbW2P06NGoqqrC/v37ZX7eTp06oVevXujfvz+8vLyQkpICFxcXpKSkYMSIEbh79269Y7u6ukIgEHCjBioq//f7T2VlJXJycuDj4yNxy3dp6Ovro7S0FK9evYKamho0NDREzj9+/Fim+DUuXrzIfRifOnWK9w/j8PBwnDx5Ui6xX/f06VOcPHkSSUlJSEpKwpUrV9CuXTv06tULK1eu5K2eGhcvXkR4eDj27NmDqqoqXn65aug2EMVCnZY6aogP44sXL3LLUuWhTZs2+P3333l51VSb4OBgGBsb46uvvpJL/IZow9tkZWXBw8ND5pGKf//9Fx4eHujYsSOOHz+OQYMGcZlt//nnH17+nSUmJmLo0KEoLi7G+PHjuVdaX331Fa5duybTnjZLlizh/n/27NkivwmrqanBxsYGw4cPh5qamkxt2LVr11tH08aPHy9T/NrI48O4RmZmJpKSknDixAn88ccfMDQ05G3kq8bjx4+RmJiIQ4cOYe/evby24cKFC0hMTOQ6eMXFxWjfvj169eqF7777jpc6APm2gSgu6rTUkbw/jAcOHIgJEyZg+PDhcokPAH/++Sd++OEHbNmyBTY2NnKpIzAwELt374aLiwvatWsnNudE1p1eG6INbxMXF4fx48fj4cOHMsfKz8/H5s2bkZ6ejqqqKnTo0AFffPGFTIn/3lRZWYni4mKRORO3b9+Gpqam2DyU+oiIiICfnx8ve9e8bw3xYVxTx4kTJ3Dq1Ck8e/YMrq6uOHfunMyxo6Ojuee/cuUKDA0N0b17d3h4eKBXr15o27atzHXo6+ujpKQELi4u3EhRjx49eNn8EmiYNhDFRp2WOpL3h/HWrVvx7bffYtKkSRIn+vKx4+7rQ+2amppidfAx1C7vnV4bog0AEBISIvI9Ywx5eXn4888/MX78eGzcuFGm+Lm5ubC0tJQ4ipCbmwsrKyuZ4td49eoVEhMTcfPmTYwdOxba2tq4f/8+dHR0FGKegLwn+taQ94fxoEGDcPr0aa4jJI86TExMuMm9Hh4ecpkDdPjw4To98927d2FhYSH1q/SGaANRbNRpqSN5fxi/7T9uvibiRkREvPW8vIbaJanvD7WGasObf981qyZ69+6NSZMmiczhqI+G+DC+c+cOfHx8kJubi7KyMly/fh0tWrRAUFAQXr58iS1bttQrroGBAa5fvw4jIyPo6+u/9fWNrJ1IJSUl5Ofni/053b9/Hy1btuQtf5K8P4znzJnDeyelvlauXIlp06bxsiqqNjo6OsjIyECLFi3kEr8h2kAaJ+q08Ky+P9QaE/qhJn9KSkp48OABjI2NRcrv3LkDR0dHPH/+XOY6hgwZAm1tbWzfvh2GhobcsuqkpCRMmTIF2dnZ9YobERGB0aNHQygUym3OyYYNGwBUv5ZdtmyZyKhQZWUlTp48idu3b8ucuFJa8v536+zsjLi4OFhaWsolPiD/NgAQWcYvDw3RBtI40ZJnnjk6Oir8D7UVK1Zg1KhRcv3Al3dfuSHaUB81r50EAgEWLlwosuy5srISqampaN++PS91nT59Gv/884/YZFhra2vcu3ev3nFf74hMmDCh3nHeZt26dQCq/51s2bIFysrK3Lmaib71HSmShbz/3d6+fRsVFRVyraMp/J7aFNpA6oc6LTyjH2qNQ33a0KFDB/z999/Q19fnlvTWpr6b2NWMDDDGkJmZKdKhUFNTg4uLC+bMmVOv2G+qbbXF3bt3eUva16tXL3z66acYMWIEr3uP5OTkcPEPHjzIy+ZrhBDFR50WQv6/wYMHc5uxDRkyRC511GR3njhxItavXy/X+Q19+/ZFeHg4tm7dCqB6dKekpASLFi1Cv379eKnD2dkZCxYswIwZM9CvXz/4+/ujX79+Mi91rlHz51VeXo6cnBy0bNlS5vlEhBDFRf/1E/L/LVq0SOLX8rBz504AwI0bN3Dz5k306NEDGhoate4wWx/r1q1Dr1694OjoiJcvX2Ls2LHIzs6GkZERfvvtN17q2LBhA8LDw3Hs2DHs3bsX48ePh7KyMkaMGIFx48ahZ8+eMsV/8eIFZsyYwU3ArplMHBgYCAsLC8yfP5+PZhCeyWunakIUd7YoUWgf+g+1x48fo0+fPmjdujX69evHbS42ZcoUzJ49m5c6LCwskJGRgTlz5mDq1KlwdXXFypUrceHCBV72aKmhpKQELy8v7Nq1Cw8ePMBPP/2Es2fP8pLuYP78+bh48SISExNF9oLx9PREVFSUzPGl9aH/u62rpvCKmTRONNLCM/qhVjeN8Yfau5bvvk7WpbxBQUFQVVVFbm6uyDbufn5+CA4Oxvfffy9T/BoaGhqYNGnSOxNA8iE/Px+RkZHYs2cPLl26hI8//ljmmDExMYiKikLnzp1F/m4cHR1x8+ZNmeNLqzH+u5VW9+7dxdIh1NWuXbswatQoiXmzXvfvv//CwsKiXnXUhSxtIIqNOi08ox9qivtDLTw8nPu6sLAQ3377Lby9veHu7g4ASE5OxpEjR7Bw4UKZn+/o0aM4cuQImjdvLlLeqlUr3LlzR+b4Na5fv47ExEQUFBSgqqpK5Nw333wjc/zi4mIcOHAAe/fuRWJiIlq0aIGxY8ciMjKSl5QUDx8+lDgq9Pz5c7n+glBcXIzjx4/D3t5epFNZn3+3FRUV8PLywk8//YTWrVu/9dqffvoJpqam9Xrm8+fPQ1VVlcuKfOjQIezcuROOjo5YvHgxN88oLi6uXvEBIDQ0FIGBgRg5ciQmT56MLl26SLyuvqsbPTw8MGnSJIwcOfKt//3K0gai4Bipl6KiIhYdHc3+/fdfkfLc3Fz26tUrqWKVl5czDw8PlpWV9c5rf/31V1ZSUiJV/Brp6ens0qVL3PcxMTFs8ODBLDQ0lJWVldUr5pvMzMyYtrY2mzRpEvvnn394ifm6nj17soiICFZaWsp77NcNGzaM/fDDD2LlP/zwAxs8eLDM8Zs1a8auX7/OfX3z5k3GGGNnz55lBgYGMsdnjLGtW7cyZWVlZmpqylxcXFj79u25w9XVlZc61NXVmbm5OZs1axY7e/YsLzFf16NHD7ZhwwbGWPWf061btxhjjH3xxRfM29ubt3pGjhzJ/X2XlpayVq1aMVVVVaaiosL2798vc3wjIyPu71te3NzcuGe9efMmU1dXZ2PGjGF2dnZs1qxZvNTx6tUrdujQITZ06FCmpqbG7O3t2cqVK1leXh4v8UNCQpipqSnT0dFhU6ZMYcnJybzEJU0HdVrqiH6o1U1T+aGmpaXFsrOzxcqvX7/OtLS0ZI7fr18/tmDBAsbY/30YV1ZWspEjR7Lhw4fLHJ8xxqysrNjKlSt5iVWbI0eOsMrKSrnF/+eff5i2tjabNm0aU1dXZ7NmzWKenp5MS0uLpaWl8VaPqakpy8jIYIxV/2JgZ2fHnj9/zjZt2sTat28vc/yQkBA2b948meO8jY6ODrtx4wZjjLGVK1cyLy8vxhhjp0+fZs2bN+e9vgcPHrDvv/+eOTs7M1VVVTZw4EAWExMj87+HV69ecb9QqaqqMgcHB/bdd9+x/Px8np6cKDLqtNQR/VCTniL/ULOysmKrV68WK1+9ejWzsrKSOf6VK1eYsbEx8/HxYWpqamzEiBHMwcGBmZqacn9HstLW1uZGcBTZpUuX2Geffcbatm3LHBwc2Lhx40RGDPmgrq7OcnNzGWOM+fv7c/8t3rlzh5dO6owZM5iOjg7r0KED+/zzz1lwcLDIwQdtbW3uFx9PT08WHh7OGKtug7q6Oi91vCklJYV9/vnnTCgUMhsbG6an9//aO/OwmtP3j79PTUe7dkZaEalk/zJmTItt8JUik61UY2SrK1lihsY3e9FmvhmixJeRJgymBS0UaYaRIsukYihZBqMyjbp/f3R1fo4TzvT5nOrkeV3X57qc5+R9P50+5z73eZ77uW8tMjU1pYyMDF70KysrKTg4mJSVlUlJSYmcnJzo1KlTvGgz5BOW0yIlT58+hY6ODgAgJSUFkyZNgqqqKsaNG4clS5Zw1q+trUVMTAxOnDiBgQMHQk1NTex5rg0ZgYZ8m8a8hpMnT2L8+PEAGvafHz58yFn/dQwMDDBs2DBcv34dN27cQEFBAWbNmgUtLS3ExsbCzs6uWbqKiopwcnKCk5MTHjx4gO+++w4rV67EihUrMHbsWPj6+nI+ubJ69Wp4e3sjMzNTlNOSm5uLlJQUxMTEcNIGGhJJL1++jOjoaCgqKqKqqgouLi68dnl2dXVFWloafHx8eNF7E4mJiUhISMDt27dRW1sr9lxzi/C9io2NzTt7TnHFyMgI586dg46ODlJSUvD9998DAP744w9eOlgXFhaif//+ABryjF6Fr9ycgQMHYs2aNRgxYgSysrIQHR0NoKFQX3PzZJri/v372LNnD2JjY3Hr1i1MnDgRx44dw4gRI1BTU4Ovv/4aHh4enHOz8vLyEBsbi/3798PAwACzZs1CeXk5/v3vf2Pu3LkIDQ3l6TdiyBWtHTXJCz169KADBw7Q8+fPSV9fXxTtX7p0iXR1dTnr29nZvfGyt7fnrE9EZG9vT+7u7hQfH09KSkqi7Y/MzEwyMTHhxQYRUUVFBYWEhFDv3r1JWVmZ3Nzc6MSJE0TUsLW2aNEiXlYrzp8/Tz4+PtSxY0cyNjamVatW0ezZs0lVVZUCAgI46+fm5tK0adOoX79+1LdvX5o2bRrl5uZy1m0p1q1bR3p6euTh4UGhoaEUEREhdvFBREQEqaur0/z580koFNKcOXNoxIgR1LFjR1qxYgUvNogaVu0KCgooPz9f7OKLb7/9lj744APS0tIiW1tb0WpgZGQk2dnZ8WZHluTn55O1tTVpamrSN998IxpfsGABTZ06lRcb48ePJyUlJbKysqKwsDB69OiRxM/cvXuXBAJBs/Tv379PoaGhZGVlRUKhkCZNmkTJyclUX18v+pkTJ07wsvrFkE9Y0CIlzKlJB3Nq0lNTU0Pnz5+no0eP0pEjR8QuPjA1NX3jZWZmxouNnj170r59+4hIPKF45cqVNH/+fM76v/zyC1lZWZGCggIJBAKxS0FBgbP+q/z888+UlJREf/75p2js2LFjlJ2dzZuNmzdvUkpKiiiR/NX7VlbU1NRQbW0tL1peXl509uzZt/5MfX09lZaWNktfSUmJevXqRZs2baLKysomf+bp06dy43MZ/MOCln8Ac2rvpj06terqanr69KnYxZXk5GTS19eX+CCWxYexLFFRURH9LfX19UV5Xzdu3ODlFJSNjQ05OztTbm4ulZSUUGlpqdglLzx8+JAcHBxEf9/G4M7Ly4sWLVrEi43bt2/TnTt3RI/Pnz9Pfn5+9N133/GiT0S0e/duevHihcT4X3/9Rbt37+akXV9fT1lZWVRVVcVJh9G+YUFLG4E5tXfTkk6tqqqK5s+fT/r6+qSgoCBxcaVbt240b948uT8RYWZmRhcuXCCihtNp27ZtI6KGU0Xa2tqc9dXV1Zs8xcU3np6eb724MnPmTBo9ejTduXNHbEUqNTWVevfuzVmfiOjjjz+m+Ph4IiIqLy8nTU1NGjp0KOnq6tLq1at5saGgoED379+XGH/48CHn90VdXR0pKSnJ/BQlQ75hibhS8q6Kort27eKk7+/vL/MKqdOmTcOXX36JmTNnoqKiAiNHjoSVlRX27t2LiooKXoqNeXp6YsyYMRIFwf788094enrC3d292dpEhBEjRuDKlSvo0aMH16m+lSVLliAjIwP//e9/4e7ujm+//RZ3797Fd999hw0bNnDWr6ysxKJFi3hNkHyduro6xMXF4dSpU00Wl0tPT+dsw8HBAUePHkX//v3h7e0Nf39/JCYm4pdffoGLiwtnfUdHR+Tn5/NSqO5t/PHHH2KP//77bxQWFuLJkye8tCNoiWKChYWFGDx4MAAgISEB1tbWyMnJESVj8/H+pjf0xvr99985d/lWUFBAjx498OjRI5m/vxnyCwtapIQ5NeloL07t6NGjiI+PF1Xo/OSTT9C9e3eYmJjgf//7H6ZPn85Jf/LkycjMzES3bt14mrEkfn5+iIuLw7hx42BtbS2TCrLbt28XBUM+Pj7Q0dFBdnY2/v3vf/NyaikmJgYeHh4oLCyEtbU1lJSUxJ6fMGECZxsAcOjQIYmx+vp6zJs3D+bm5pz1q6qqmqwS/fDhQ1Fnca78/fffIq2TJ0+KXptevXqJels1l379+kEgEEAgEMDR0VGs03ZdXR1KSkowZswYTjYAYNOmTViyZAmio6NhbW3NWY/R/mBBi5Qwp/Z22ptTe/z4MczMzAAAmpqaol5DH3/8MebOnctZf+vWrXB1dcWZM2dgY2Mj8WHs6+vL2cb333+PhIQEjB07lrPWm1BQUICCwv/3XZ0yZQqmTJnCm/7Zs2eRnZ2N5ORkiecEAgHq6up4s/U6CgoK8Pf3h52dHZYuXcpJa/jw4YiPj0dwcDCAhrnX19cjJCQE9vb2fEwXVlZW2LZtG8aNG4cTJ06IbN27dw+6urqctCdOnAgAuHTpEkaPHg11dXXRc0KhEKamppg0aRInGwAwY8YMVFdXw9bWFkKhUKKUP9eeXwz5hwUtHGBO7f9pb07N3NwcpaWlMDExQe/evZGQkIDBgwfj6NGj0NLS4qy/b98+pKamQkVFBZmZmWKrIAKBgJegRSgUynxbJTY2Furq6nB1dRUbP3jwIKqrq+Hh4cFJ39fXFzNnzsTKlStlupX2JoqLi/Hy5UvOOiEhIbCzs8Mvv/yC2tpaLF26FFeuXMHjx4+Rk5PDw0yBjRs3wtnZGSEhIfDw8ICtrS0A4McffxStsDaXoKAgAICpqSk+//xzXmrXNEVYWBhrOst4KwKidtDhrxX56aef4OHhgQcPHnDSuXr1Kuzs7DBgwACkp6djwoQJYk6Nj22EzMxMODs749mzZ/Dw8BDl4axYsQLXrl1DUlISZxu7d++WqVOLi4t7q1Pj+iHZSFhYGBQVFeHr64uMjAyMGzcOdXV1ePnyJbZs2QI/Pz9O+p07d4avry8CAwPFVir4ZPPmzbh16xa2bt0qsw+Cnj17Ytu2bRKBdVZWFr788ktcv36dk76GhgYuXbok0200AFi0aJHYYyJCeXk5jh8/Dg8PD2zdupWzjYqKCkRHR+PChQuor69H//79eS0mCDSsaj579gza2tqisdLSUqiqqjbZeJLBkDdY0CIlzKm9PzTVlff27dv45Zdf0K1bN9E3WC7o6Ojg559/5v3D+PXk1/T0dOjo6MDKykpiC4qPIFVZWRnXrl2Dqamp2HhpaSksLS1RU1PDSd/DwwOffPIJvvjiC0467+L1oEtBQQH6+vpwcHCAl5eX2HZnc7h9+zaMjIyaDB5v374NY2NjTvqNvHz5EpmZmSguLsa0adOgoaGBe/fuQVNTU2z185+go6ODGzduQE9PD9ra2m8NgLmudCoqKqK8vFzCFz169AgGBgYy3Q5kyAdse0hKfv31V7HHjU5t8+bN7zxZJA2NTm316tVNPseXUyMiXLhwQcypCYXCJvNppKW9OTUlJSUUFhaK/R7Gxsa8/Q2Ahg/jAwcOYMWKFbxpApBIdnZ2duZV/3UMDAxw+fJliaAlPz+f85YjAFhYWGD58uXIzs6WWe4PAGRkZPCi8ybMzMzeeN+amZnxct+WlZVhzJgxuH37Nv766y+MHDkSGhoa2LRpE168eIFt27Y1SzcsLAwaGhqif8ty++ZN36H/+usvCIVCmdllyA8saJES5tTeTHt0au7u7ti5cycvx5uboq6uDps2bUJqair69Okj8WHc3F5TsbGxfExPatzc3ODr6wsNDQ0MHz4cQMPWkJ+fH9zc3Djrx8TEQF1dHVlZWcjKyhJ7jq/cn5bgTafqnj9/zttWqp+fHwYOHCgRMDo7O3NaqXp1y3XWrFlcpvhGIiMjATT8TRv/5o3U1dXh9OnT6NWrl0xsM+QLFrS0EZhTezst7dRk3cCyoKAA/fr1A9BwFP1V+Ar6HBwckJSUJJE4/OzZM0ycOJGXOi1r1qxBWVmZ2Imx+vp6uLu7Y926dZz1S0pKOGu8if79++PUqVPQ1tYWnX57E81t/Ni4rSwQCLBy5UqxFc26ujqcP38effv2bZb262RnZyMnJ0cieDcxMcHdu3d5sWFvb48ZM2Zg8uTJnEsYvEpYWBiABj+4bds2KCoqip5rTORv7pcqRvuCBS1vgTm1f057cWqy7sor65U7oCHx+vWuywDw4sULnDlzhhcbQqEQBw4cQHBwMPLz86GiogIbGxuYmJjwoi9LnJycRCUAGk+/8U3jtjIRoaCgQOy9JxQKYWtri8WLF/Niq76+vskV2d9//120EsoVGxsbfP3111iwYAHGjh2LmTNnYuzYsZxXORuDU3t7eyQlJYnl3DEYr8KClrfAnNo/p704tZYIKmTF5cuXRf++evUqKioqRI/r6uqQkpICQ0NDXm1aWFiIkpb5hIiQmJiIjIyMJqv6ckkmbjzG+/q/+aTxPvL09ERERAQ0NTVlYgcARo4cifDwcGzfvh1AQ3D9/PlzBAUF8VarJzIyEuHh4Th58iT27dsHDw8PKCoqYvLkyZg+fTo+/fRTTvqNr1dtbS1KSkrQrVs3zknQjPYFOz3URmgJp/b555+jY8eO2L59OzQ0NHD58mXo6+vDyckJxsbGvOVD1NfXi5zaoUOHeHVqjcijU3NxcUFcXBw0NTXfWeKey4exgoKCaDWoqbe3iooKoqKieEkgl3WrAF9fX2zfvh329vbo1KmTxCpXS+fwcOW3335DcXExhg8fDhUVlTduCzeHe/fuwd7eHoqKirh58yYGDhyImzdvQk9PD6dPn5bJ6cAXL17g6NGjWLt2LQoKCjjn3tXU1GDBggXYvXs3gIZVTnNzc/j6+qJLly4IDAzkY9oMOYYFLW0M5tTejjw7NU9PT0RGRkJDQwOenp5v/VkuH8ZlZWUgIpibmyMvLw/6+vqi54RCIQwMDMS217iwYMECUauADz/8UOJebdzWay46OjrYu3evTKr6vuuk26twPfX2+PFjuLq6IiMjAwKBADdv3oS5uTm8vb2hpaXFS28xoOH9sX//fly8eFFUNmH69OkSRRj5oKKiAt9//z327t2LixcvYtCgQTh//jwnTT8/P+Tk5CA8PBxjxozB5cuXYW5ujh9//BFBQUESpzgZ7yEt1JhRLtHS0iJtbW2pLq48evRI5l2eiYiqq6tp586dNH/+fJo7dy7t2LGDqquredN/lfLycgoLC6MBAwaQQCCgwYMHc9b09fWlAQMG0JkzZ0hNTU30Oh05coT69u3LWb8lqK+vp9LS0hbpVi1rdHV16fjx4zLTNzU1paKiIplox8XFia7NmzeTtrY2ubm5UUREBEVERJCbmxtpa2vTli1bONtqiS7PLcHTp09p165dNGLECPrggw/IwsKCvvnmG946cRsbG9O5c+eIiMRep5s3b5KGhgYvNhjyDVtpeQuN3+aBhqPHa9aswejRozF06FAAwLlz55CamoqVK1fC39+fky13d3dUVlYiJiYGlpaWyM/Ph7m5OdLS0uDv748rV65w0m8pnj17hh9++AH79u1DZmYmzM3NMW3aNEyfPp2XkvImJiY4cOAAhgwZAg0NDdHr9Ntvv6F///549uwZD7+FbKmvr4eysnKLdKsuLi5GeHg4ioqKIBAIYGlpCT8/P96K2nXp0gWZmZkyyWcBGt6DKSkp2LVrl0xWCxqZNGkS7O3tsWDBArHxrVu34uTJkzh8+DAn/c6dOyM1NRW2trZi921JSQlsbGzw/PlzTvqN3LhxA5mZmU1u1fHREFVFRQXa2tqYMmUKpk+fjkGDBnHWfBVVVVUUFhbC3Nxc7HXKz8/H8OHD8fTpU17tMeQP+UgGaCVePco7adIk/Oc//xFzar6+viKnxjVoaYkuz4DsnVqnTp1ETm3dunW8O7UHDx40uY1VVVUlNz1LWqpbdWpqKiZMmIC+ffti2LBhICKcPXsWVlZWOHr0KEaOHMnZRkBAACIiImTWKsDV1RX79++HgYEBTE1NJerZNPfU3uukpqZi48aNEuOjR4/mZcuxJRqi7tixA3PnzoWenh46d+4s0c+Kj/f3kSNHMGLECJm1nhg0aBCOHz+OhQsXAvj/k3o7duwQfVlkvN+woEVKmFOTDubUpKMlulUHBgbC399fokBeYGAgli1bxkvQkp2djYyMDCQnJ8ukVcCsWbNw4cIFzJgxo8lEXL7Q1dXFoUOHsGTJErHxw4cP81LZtyUaoq5ZswZr167FsmXLeNFrilGjRslMGwDWr1+PMWPG4OrVq3j58iUiIiJw5coVnDt3TqK4IOP9hG0PSYmJiQkWLFgg4dRCQkKwdetWzqsh48aNQ//+/REcHCw62WNiYgI3NzfU19cjMTGRkz7Q8DvMmzdPpk5N1pw9exZjxozB9OnTERcXhzlz5og5tQEDBrT2FKVCW1sb1dXVePnypcy6VSsrK6OgoEBiNefGjRvo06cPXrx4wdmGLBOKAUBNTQ2pqan4+OOPOem8i7i4OHh7e2PMmDGi4Dc3NxcpKSmIiYnhXDSxJRqiampq4tKlSzA3N+es9TYSExORkJCA27dvS9QB4mPlq6CgAKGhoWI92JYtWwYbGxvO2gz5h620SMnq1avh7e2NzMzMJp0aV1qidf0ff/wBV1dXXrTehiyd2kcffYScnByEhoaiW7duSEtLQ//+/XHu3Dm5cmrh4eEyt6Gvr49Lly5JBC2XLl3i7aSYrI8cGxkZybQMQCOzZs2CpaUlIiMjkZSUBCJC7969kZOTg3/961+c9Xv37o3Lly8jOjoaioqKqKqqgouLC68NUV1dXZGWlgYfHx9e9JoiMjISX331FTw8PHDkyBF4enqiuLgYP//8M+bPn8+LDRsbG7F8QgbjVdhKyz/g/PnziIyMRFFRkcip+fr68uLUANl3efb29sagQYNazKnt2LFDwqmtXbtWZrYZ4vznP/9BWFgYAgMD8dFHH0EgECA7OxsbN25EQEAAvv76a95sPXjwANevX4dAIICFhYXYMWsuHD9+HFFRUdi2bZtEU0aGOOvXr8eWLVswbtw4mTWX7NWrF4KCgjB16lSxRNlVq1bh8ePHvHS7B4DKysom8+769OnDiz5DfmFBy3sEc2pti+LiYsTGxqK4uBgREREwMDBASkoKjIyMYGVlxVmfiBAeHo7Nmzfj3r17ABpO+yxZsgS+vr685IdUVVVh4cKFiI+PF/0tFBUV4e7ujqioKE7dwwHxbTRVVVWJe5aPbbTXqampwd9//y02xsdqz4sXL3D58uUm79sJEyZw1jczM3vjcwKBALdu3eJsQ1VVFUVFRTAxMYGBgQFOnDgBW1tb3Lx5E0OGDMGjR4846V+4cAEeHh6iL4avIhAIeGkcy5BvWNDSDJhTezPMqUlHVlYWPvvsMwwbNgynT59GUVERzM3NsWnTJuTl5fGSw/Qqf/75JwDw1q6hkTlz5uDkyZPYunUrhg0bBqAhOdfX1xcjR45EdHQ0J/24uLi3BlevnvDjQnV1NZYuXYqEhIQm71Gu91VKSgrc3d3x8OFDiefk6b41NzdHYmIi+vfvj0GDBuGLL77AnDlzkJaWBjc3N85BZJ8+fdC9e3csW7asycRreehpxZAxLV8aRj6pqqqi+fPnk76+PikoKEhcXElOTiZ9fX0SCAQSFx/6LYWZmRlduHCBiIgGDhxI27ZtI6KGIlp8FOGzsbEhZ2dnys3NpZKSEiotLRW75IUhQ4bQ5s2biUi8iFZeXh516dKFV1uVlZV05swZys7OpgcPHvCqraurSxkZGRLj6enppKenx6stWTJv3jyytLSkgwcPkoqKCu3atYuCg4Opa9eutHfvXs763bp1o3nz5lFFRQUPs209vL296ZtvviEioujoaFJRUaERI0aQlpYWeXl5cdZXV1fnrVAdo33CghYpYU5NOphTkw41NTW6desWEYkHLSUlJdShQwdebDx//pw8PT1JUVFRFAB/8MEH5OXlxVs1XhUVFbp69arEeGFhIamqqnLW//TTT2n37t0yq9rciJGRkSj40tDQEN1j8fHx9Nlnn3HW19DQoN9++42zztt4+fIlxcTE0NSpU8nR0ZHs7e3FLj6oq6ujv//+W/T4wIEDtHDhQoqIiKC//vqLs76TkxMlJiZy1mG0X9j2kJQYGxsjPj4ednZ20NTUxMWLF9G9e3fs2bMH+/fvx08//cRJX1NTE7/++itvlUqbQtbN7YCGaq/19fWiJoYJCQnIzs5G9+7d4ePjw7nb88SJEzFz5kxMmjSJ81xbk65duyIhIQEfffSRWO7PoUOHsHjxYhQXF3O2IeutGwBwdHSErq4u4uPjoaysDKBh+9TDwwOPHz/GyZMnOekHBATgf//7H2pqajBlyhR4e3tjyJAhnOf9Ourq6rhy5QpMTEzQtWtXJCUlYfDgwbxVrPXy8sKwYcPg7e3N04wlkXUfqJbg4cOH8PDwwODBg2FtbS2Rw8THNjlDvmFBi5Qwp9Y2aC9ObenSpTh37hwOHjwICwsLXLx4Effv34e7uzvc3d0RFBTE2Yaenh4SExNhZ2cnNp6RkYEpU6bgwYMHnG0UFBTgs88+w4sXL2BrawuBQIBLly6hQ4cOSEtL4yWhuK6uDseOHUNsbCx++ukndO/eHV5eXpg5cyY6derEWR9oyKWIiorCp59+ilGjRqFPnz4IDQ1FZGQkNm3ahN9//52TfnV1NVxdXaGvry+zJHg9PT3Ex8fLpLlkI7GxsVBXV5conXDw4EFUV1dzzjH68ccfMXPmTFEO1qvIU+4PQ4a07kKP/GBjY0OZmZlERDRy5EgKCAggIqKIiAgyNDTkrF9VVUVjx44lDw8PCg0NFTVta7z4QNbN7YiIdu3aRQkJCRLjCQkJFBcXx1n/yJEjpKmpKfe5P7W1tTRt2jRSUFAggUBASkpKJBAIaMaMGfTy5UtebMh666aR6upq2r59Oy1atIj8/f1l2oSzsrKSgoODSVlZmZSUlMjJyYlOnTrFWXfLli2i91l6ejqpqKiQUCgkBQUFCg8P56y/Y8cOUlRUJHV1dTIxMSFTU1PRZWZmxlmfiOjDDz+k69ev86L1JiwsLCg9PV1iPDMzkywsLDjrm5iY0Pz58+V+m5whO1jQIiXMqUkHc2r/jOLiYjpw4AAlJCTwnqvj4OBArq6uVFNTIxqrrq4mV1dXcnR05MXGunXraOfOnRLjO3fupA0bNvBio5Hz58+Tj48PdezYkYyNjWnVqlU0e/ZsUlVVFX2JaA61tbVkZ2cn9t4oKyujH374gS5dusTH1KlTp060du1aqqur40WvKUJDQ2nevHlUX18vMxsdOnSgkpISifGSkhJSVlbmrK+uri7z3B+GfMOCFilgTk16mFOTnpiYGLKysiKhUEhCoZCsrKxox44dvOkXFBSQoaEh6erqkoODAzk6OpKuri4ZGhpSYWEhLzZMTEwoJydHYjw3N5dMTU0569+/f59CQ0NFr9OkSZMoOTlZ7B4+ceIEqampcbKjp6dHN27c4DrdN6KtrS2T+9bZ2Vns6tixI5mZmdH48eMlnuMDIyMjOnLkiMT44cOHeVlxdnd35/U9wGh/sDL+UqCkpITCwkKxHBBjY2MYGxvzZqO2thaff/45740GXVxcxB6np6fLrLkdABgYGODy5csS1Uvz8/N5aTzn4uKCjIwMmSYstwQrV65EWFgYFi5cKGoLce7cOfj7+6O0tBRr1qzhbMPa2ho3b97E3r17ce3aNRAR3NzcMH36dIleR82loqKiyYrN+vr6KC8v56zftWtXdOvWDV5eXpg1a1aTlXYHDx7MuZu4u7s7du7cKdFcki88PDxw4MABrFixglfdjh07ij12dnbmVf913Nzc4OvrCw0NDQwfPhxAQ80hPz8/uLm5cda3sLDA8uXLkZ2dLbPcH4Z8wxJxpSQgIABKSkoyc2r+/v7Q19fn3am9q6Hdq/DRR6axQFdsbKyYU/Py8sLkyZMRGhrKSX/t2rUIDw+XaVXflkBPTw9RUVGYOnWq2Pj+/fuxcOHCJouQtUV69OiBoKAgzJgxQ2x8z549CAoK4lyw8PTp0xgwYADU1NQAAGVlZTh06BAsLS0xevRoTtqv0ljVt3v37hg4cKDIXiNbtmzhpO/r64v4+HjY2tqiT58+EvctV/2Wora2FjNnzsTBgwdFJwTr6+vh7u6Obdu2cT4d2BIFMBnyDQtapIQ5NelgTk06tLW1kZeX12QH5sGDB+PJkye82Ll79y5ycnKaPOLOR4C3ceNGhISEICQkBA4ODgCAU6dOYenSpQgICMDy5cs56Y8aNQouLi7w8fHBkydP0LNnTwiFQjx8+BBbtmzB3LlzOf8OAGBvb//G5wQCAedyALLWBwAHBwckJSVBS0tLbPzZs2eYOHEiLzYauXHjBvLz86GiogIbGxtWqZbRYrCgRUqYU/tnMKf2dhYuXAglJSWJYHTx4sWoqanBt99+y9lGbGysqDaOrq6u2PYmXwEeESEwMBCRkZGijt7KyspYtmwZVq1axVlfT08PWVlZsLKyQkxMDKKiovDrr7/ihx9+wKpVq1BUVMTZRntBQUEBFRUVEh28KysrYWhoKNF6hMGQR1jQ8h7BnFrboXHlzsjISFQsLTc3F3fu3IG7u7vYSltzV9mMjIzg4+OD5cuX854r9TrPnz9HUVERVFRU0KNHD3To0IEXXVVVVVy7dg3GxsaYMmUKrKysEBQUhDt37qBnz56orq7mxY48c/nyZQBA3759kZ6eDh0dHdFzdXV1SElJwXfffYfS0lLOtmRdoJKIkJiYiIyMjCb1+ci7Y8g3LBH3PaDRqQHA1atXUVFRIXrc6NQMDQ15scWcmnQUFhaif//+ACCqfquvrw99fX0UFhaKfo5LJ+bq6mq4ubnJPGABGoovck2GbYru3bvj8OHDcHZ2RmpqKvz9/QE0BNp8NCmVJS4uLoiLi4OmpqZEQvzrcLlv+/btC4FAAIFAINqiexUVFRVERUU1W/9V/Pz8RAUqra2teekU/rr+9u3bYW9v32TDRAaDBS2tCHNqzdNvD04tIyND5ja8vb1x8OBBBAYGytyWrFi1ahWmTZsGf39/ODo6ik5apaWloV+/fq08u7fTsWNH0f35+ikfPikpKQERwdzcHHl5eWInrIRCIQwMDKCoqMiLre+//x4JCQkyq7q7d+9eJCUlybSqL0O+YdtDrYinpyciIyOhoaHxzlM+XE72lJWVtZhTk3UpcR0dHezdu5c5NSmoq6vD+PHjUVNT0+RJK3lJ7q6oqEB5eTlsbW1Fq0Z5eXnQ1NREr169Wnl274aIcPv2bejr60NVVbW1p8OJLl26IDMzExYWFjLRNzMzQ3Jyslz8XRmtAwta2gDMqUkPc2rSExwcjKCgIPTs2VNiVYqv5G7Gu6mvr4eysjKuXLkicVqMb4qLixEeHo6ioiIIBAJYWlrCz8+Pt7pGmzdvxq1bt7B161aZrHLu3r0bKSkp2LVrF2+1hBjtCxa0tAGYU5Me5tSkR1tbG2FhYZg1a1ZrT+W9x8rKCjt37pRJh+pGUlNTMWHCBPTt2xfDhg0DEeHs2bPIz8/H0aNHMXLkSM42nJ2dkZGRAR0dHZkUqKyuroaLiwtycnJgamoqoX/x4kVO+gz5h+W0tAEUFBTQo0cPPHr0SKZBy5ucmpWVFW9OLTs7GxkZGTKruuvq6or9+/fDwMCAObV30KFDBwwbNqy1p8EAsGnTJixZsgTR0dGwtraWiY3AwED4+/tLFMAMDAzEsmXLeHl/a2lpybTq7qxZs3DhwgXMmDFDrnPWGLKDrbS0EY4fP44NGzbI1Kn169cPo0ePbtKppaWl8fKBL8vcHACYMmUKMjIyMHny5CadWlBQECf99sT69etRXl6OyMjI1p7Ke4+2tjaqq6vx8uVLCIVCiVXCx48fc7ahrKyMgoKCJgsW9unTBy9evOBsQ9aoqakhNTUVH3/8cWtPhdFGYSstbYQZM2aguroatra2MnNqRUVFSEhIkBj38vJCeHg4Z32An1YAb+P48ePMqUlJXl4e0tPTcezYMZn1mmJIB1/vr7ehr6+PS5cuSQQtly5dkqjNxJUHDx7g+vXrEAgEsLCwaLInVHMwMjJq80fZGa0LC1raCMypSQdzatKjpaX1zqP0jJbBw8ND5jZmz56NL7/8Erdu3cJHH30EgUCA7OxsbNy4EQEBAbzYqKqqEhVGbKyRpKioCHd3d0RFRXE+SLB582YsXboU27Ztk2i6ymAAAFqqnTSj9Vm9ejVpaWnRhg0b6PTp03TmzBlav349aWlpUXBwMC82nj9/Tp6enqSoqEgCgYAEAgF98MEH5OXlRVVVVZz1jx07RqNHj6aSkhLuk23nVFdX0/Pnz0WPS0pKKCwsjFJSUlpxVu8vv/32G3311Vfk5uZG9+/fJyKi5ORkKiws5EW/vr6etmzZQoaGhqL3nqGhIYWHh1N9fT0vNr788ksyNzenn376iZ4+fUpPnz6l48ePU7du3cjHx4ezvpaWFgmFQlJQUCB1dXXS1tYWuxgMltPShiguLkZsbCyKi4sREREBAwMDpKSkwMjICFZWVpz1iQjh4eHYvHkz7t27B6DhiPKSJUvg6+vLS9LbnDlzcPLkSWzdulWUBJqdnQ1fX1+MHDkS0dHRnPRfzQ1QVVWV2PLgYxutvfB6s8FevXpBSUmJ92aDjHeTlZWFzz77DMOGDcPp06dRVFQEc3NzbNq0CXl5eUhMTOTV3p9//gkA0NDQ4FVXT08PiYmJsLOzExvPyMjAlClT8ODBA076cXFxb/VDLbFixWjbsKCljcCcmnQwpyY9rNlg22Ho0KFwdXXFokWLoKGhgfz8fJibm+Pnn3/GxIkTcffuXd5svbo127NnT+jp6fGmraqqigsXLsDS0lJs/MqVKxg8eDCqqqp4s8VgNEmrrvMwRAwZMoQ2b95MRETq6upUXFxMRER5eXnUpUsXXm1VVlbSmTNnKDs7mx48eMCrtoqKCl29elVivLCwkFRVVXm1xXg7KioqVFZWRkRErq6u9M033xAR0e3bt0lFRaU1p/beoaamRrdu3SIi8fd3SUkJdejQgRcbst6aJSJycHAgV1dXqqmpEY1VV1eTq6srOTo6ctb/9NNPaffu3VRdXc1Zi9E+kX0nNYZUFBQUNFn/QF9fH48ePeLFRlVVFby8vPDhhx9i+PDh+OSTT/Dhhx/C29ubt265Q4cORVBQkNjxypqaGqxevVrUN4YLdnZ2iI+PR01NDWet9k5js8E7d+4gNTUVo0aNAiAfzQbbG1paWigvL5cY//XXX3lrVrpo0SJkZWXh6NGjePLkCZ48eYIjR44gKyuLt0Tc8PBwnD17Fl27doWjoyNGjBgBIyMj5OTkICIigrP+gAEDsHTpUnTu3BmzZ89Gbm4uD7NmtCtaO2piNGBoaEg5OTlEJP5NLCkpiczNzXmxIeskOiKiy5cvk6GhIenq6pKDgwM5OjqSrq4udenShZeEw0WLFlGnTp1IU1OTvvjiCzp37hwPs26fHDx4kJSUlEhBQYFGjhwpGl+3bh2NGTOmFWf2/rFkyRL6+OOPqby8nDQ0NOjmzZuUnZ1N5ubmohUwrujq6lJGRobEeHp6Ounp6fFig6hhZWX79u20aNEi8vf3px07dvC6MvLy5Us6fPgwOTk5kZKSEllaWlJISAhVVFTwZoMhv7CgpY3AnJr0MKcmPeXl5XTx4kWqq6sTjZ0/f56KiopacVbvH7W1tTRt2jRSUFAggUBASkpKJBAIaMaMGfTy5UtebLTE1uy6deto586dEuM7d+6kDRs28GLjVSorKyk4OJiUlZVJSUmJnJyc6NSpU7zbYcgPLGhpIzCn1jyYU2PIE8XFxXTgwAFKSEigmzdv8qot63wTIiITExPRivCr5ObmkqmpKS82Gjl//jz5+PhQx44dydjYmFatWkWzZ88mVVVVCggI4NUWQ35gQUsbgzk16WFOjSFPxMTEkJWVFQmFQhIKhWRlZUU7duzgTb+goKDJrVlDQ0PeasF06NBBlFD8KsXFxbwkFN+/f59CQ0NFr9OkSZMoOTlZrM7MiRMnSE1NjbMthnzCgpY2BHNq74Y5NYY88vXXX5OamhoFBgbSkSNH6MiRIxQYGEjq6ur01Vdf8WZH1luz3bt3pz179kiMx8fHk5mZGWd9JSUl6tWrF23atIkqKyub/JmnT5+SnZ0dZ1sM+YQFLW0E5tSkgzk1hjyiq6tL+/btkxjft28f6erqtsKMmseGDRtIV1eXdu3aRaWlpVRaWko7d+4kXV1dWrduHWf9rKwssSrOpaWlrIozQwxWXK6NoKenh6ioKEydOlVsfP/+/Vi4cCEePnzYSjP7Z2zcuBEhISEICQmBg4MDAODUqVNYunQpAgICsHz5ck76p0+fxoABA6CmpgYAKCsrw6FDh2BpaYnRo0dznj+DIQu0tbWRl5fXZAfmwYMH48mTJ7zYuXv3LnJyclBZWSnqDdSIr68vZ30iQmBgICIjI1FbWwugobv0smXLsGrVKs76r1dx7tmzJ4RCIavizBDBgpY2AnNq0sGcGkMeWbhwIZSUlLBlyxax8cWLF6OmpgbffvstZxuxsbHw8fGBUCiErq6uWOVogUCAW7ducbbRyPPnz1FUVAQVFRX06NEDHTp04EWXVXFmvAsWtLQRmFOTDubUGPJIY2dkIyMjDBkyBACQm5uLO3fuwN3dXayH1us+QFqMjIzg4+OD5cuXQ0FBPuuGqqqq4tq1azA2NsaUKVNgZWWFoKAg3LlzBz179uStCCZDfmFBSxuBOTXpYE6NIY/Y29tL9XMCgQDp6enNsqGrq4u8vDx069atWf+/LdCnTx988cUXcHZ2hrW1NVJSUjB06FBcuHAB48aNQ0VFRWtPkdHKsKCljcCcmnQwp8ZgNM3SpUuho6ODwMDA1p5Ks0lMTMS0adNQV1cHR0dHpKWlAQDWr1+P06dPIzk5uZVnyGhtWNDyHsGcGoPRfqmrq8P48eNRU1MDGxsbsdVZoPkrtC1NRUUFysvLYWtrK1oRzsvLg6amJnr16tXKs2O0NixoeY9gTo3BaL8EBwcjKCgIPXv2RKdOnSRy1pq7QstgtCVY0PIewZwag9F+0dbWRlhYGGbNmtXaU2EwZAYLWt4jmFNjMNovnTt3xpkzZyTKJjAY7Qn5PELCaBYdOnTAsGHDWnsaDAZDBvj5+SEqKqq1p8FgyBS20vIesX79epSXlyMyMrK1p8JgMHjG2dkZ6enp0NXVhZWVlUTOWlJSUivNjMHgjw9aewKMliMvLw/p6ek4duwYc2oMRjtDS0sLLi4urT0NBkOmsKDlPYI5NQaj/fLf//4X9fX1or5cpaWlOHz4MOvLxWhXsO2h94iamhrm1BiMdsrrfbl69eoFJSUl1peL0a5gibjvEU5OTtizZw8A4MmTJxgyZAg2b96MiRMnIjo6upVnx2AwuHDx4kV88sknABqKMHbq1AllZWWIj49neWyMdgMLWt4jmFNjMNov1dXV0NDQAACkpaXBxcUFCgoKGDJkCMrKylp5dgwGP7Cg5T2COTUGo/3SvXt3HD58GHfu3EFqaipGjRoFAKisrISmpmYrz47B4AcWtLxHMKfGYLRfVq1ahcWLF8PU1BT/+te/MHToUAANX1D69evXyrNjMPiBJeK+R7BmgwxG+4b15WK0d1jQ8p7BnBqDwWAw5BUWtDAYDAaDwZALWE4Lg8FgMBgMuYAFLQwGg8FgMOQCFrQwGAwGg8GQC1jQwmAwGAwGQy5gQQuDwWAwGAy5gAUtDAaDwWAw5AIWtDAYDAaDwZAL/g/iyXtbOesMPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97e3072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='diagnosis', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(data=df,x='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2975139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8fdcc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c94ea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis\n",
       "0           M\n",
       "1           M\n",
       "2           M\n",
       "3           M\n",
       "4           M\n",
       "..        ...\n",
       "564         M\n",
       "565         M\n",
       "566         M\n",
       "567         M\n",
       "568         B\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj=df.select_dtypes(object)\n",
    "df_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff84a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num=df.select_dtypes(['float64','int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215f6871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e55c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df_obj.columns\n",
    "for i in df_obj:\n",
    "    df_obj[i]=le.fit_transform(df_obj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40f3917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis\n",
       "0            1\n",
       "1            1\n",
       "2            1\n",
       "3            1\n",
       "4            1\n",
       "..         ...\n",
       "564          1\n",
       "565          1\n",
       "566          1\n",
       "567          1\n",
       "568          0\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d22d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum=pd.concat([df_num,df_obj],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c5676aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0                  0.2654          0.4601                  0.11890          1  \n",
       "1                  0.1860          0.2750                  0.08902          1  \n",
       "2                  0.2430          0.3613                  0.08758          1  \n",
       "3                  0.2575          0.6638                  0.17300          1  \n",
       "4                  0.1625          0.2364                  0.07678          1  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564                0.2216          0.2060                  0.07115          1  \n",
       "565                0.1628          0.2572                  0.06637          1  \n",
       "566                0.1418          0.2218                  0.07820          1  \n",
       "567                0.2650          0.4087                  0.12400          1  \n",
       "568                0.0000          0.2871                  0.07039          0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e42490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_sum.drop('diagnosis',axis=1)\n",
    "Y=df_sum['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "270dc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=1)\n",
    "\n",
    "# Apply random oversampling to your data\n",
    "x_rosample, y_rosample = ros.fit_resample(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ad474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6198b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(x_rosample,y_rosample,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1679240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d7c258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df60d6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de923323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64449c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "429b0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bd145c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01453352, -0.61557849, -0.9992333 , ..., -0.44344203,\n",
       "        -0.22496369,  1.70231118],\n",
       "       [-0.73523443, -0.19844267, -0.77958467, ..., -1.11872543,\n",
       "        -0.06848194, -0.18529747],\n",
       "       [-0.82181715,  0.10152018, -0.80232094, ..., -0.68859694,\n",
       "         0.38218552, -0.23567568],\n",
       "       ...,\n",
       "       [ 0.7003629 ,  1.11858169,  0.74455759, ...,  1.00396479,\n",
       "         0.60908407,  2.59967308],\n",
       "       [-0.18501522,  0.35227037, -0.24650028, ..., -0.68034874,\n",
       "        -1.09187262, -0.42984171],\n",
       "       [-0.46431431, -0.31092873, -0.53801177, ..., -1.13094499,\n",
       "        -1.46586401, -1.18971308]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa87eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22121484, -0.79602489, -1.24040019, ..., -1.5329685 ,\n",
       "        -0.37988063, -0.54424223],\n",
       "       [ 0.29537922,  0.1179244 ,  0.27359195, ...,  0.36243792,\n",
       "         1.67316   ,  1.15654721],\n",
       "       [-0.48945123, -0.83820716, -0.51486949, ..., -0.61543233,\n",
       "         0.58404699, -0.31596596],\n",
       "       ...,\n",
       "       [-1.57815908, -0.19844267, -1.45314673, ..., -0.14772869,\n",
       "         0.33054654,  1.10931764],\n",
       "       [-0.39728253, -0.63901309, -0.45924683, ..., -0.41839193,\n",
       "        -0.6537237 , -0.42669307],\n",
       "       [-1.22959382,  1.84271074, -1.22578401, ..., -0.50255415,\n",
       "        -1.09187262, -0.08034286]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a6fc803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d343446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred=lr.predict(X_test)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f52977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual op</th>\n",
       "      <th>predict op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual op  predict op\n",
       "546          0           0\n",
       "223          1           1\n",
       "403          0           0\n",
       "8            1           1\n",
       "394          0           0\n",
       "..         ...         ...\n",
       "268          0           0\n",
       "307          0           0\n",
       "318          0           0\n",
       "224          0           0\n",
       "555          0           0\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={\"Actual op\":Y_test,\"predict op\":ypred}\n",
    "df11=pd.DataFrame(dict)\n",
    "df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b22bc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767441860465116"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f22361f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 96   4]\n",
      " [  1 114]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6107e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d95942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae6d5c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       100\n",
      "           1       0.97      0.99      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2f3938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 2d array into 1d drray\n",
    "TP,FP,FN,TN=confusion_matrix(Y_test,ypred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1253514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 96\n",
      "false postive 4\n",
      "False Negative 1\n",
      "True Negative 114\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive\",TP)\n",
    "print(\"false postive\",FP)\n",
    "print(\"False Negative\",FN)\n",
    "print(\"True Negative\",TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1c63617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f2dc05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model):\n",
    "    model.fit(X_train,Y_train)\n",
    "    ypred=model.predict(X_test)\n",
    "    print(classification_report(Y_test,ypred))\n",
    "    print(confusion_matrix(Y_test,ypred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33f0fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing decisionTree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04d6b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       100\n",
      "           1       0.92      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  2 113]]\n",
      "random_state 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       100\n",
      "           1       0.93      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  2 113]]\n",
      "random_state 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       100\n",
      "           1       0.92      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  2 113]]\n",
      "random_state 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       100\n",
      "           1       0.90      0.98      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  2 113]]\n",
      "random_state 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       100\n",
      "           1       0.94      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.97      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  1 114]]\n",
      "random_state 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "random_state 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       100\n",
      "           1       0.92      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  2 113]]\n",
      "random_state 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       100\n",
      "           1       0.93      0.97      0.94       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  4 111]]\n",
      "random_state 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  3 112]]\n",
      "random_state 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  3 112]]\n",
      "random_state 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       100\n",
      "           1       0.93      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  2 113]]\n",
      "random_state 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       100\n",
      "           1       0.92      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  3 112]]\n",
      "random_state 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "random_state 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       100\n",
      "           1       0.92      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  3 112]]\n",
      "random_state 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       100\n",
      "           1       0.92      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  2 113]]\n",
      "random_state 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       100\n",
      "           1       0.90      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.93      0.92      0.92       215\n",
      "weighted avg       0.93      0.93      0.93       215\n",
      "\n",
      "[[ 87  13]\n",
      " [  3 112]]\n",
      "random_state 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "random_state 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       100\n",
      "           1       0.93      0.97      0.94       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  4 111]]\n",
      "random_state 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       100\n",
      "           1       0.91      1.00      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  0 115]]\n",
      "random_state 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93       100\n",
      "           1       0.90      0.99      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 87  13]\n",
      " [  1 114]]\n",
      "random_state 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       100\n",
      "           1       0.94      0.97      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  3 112]]\n",
      "random_state 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       100\n",
      "           1       0.93      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  2 113]]\n",
      "random_state 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       100\n",
      "           1       0.91      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  1 114]]\n",
      "random_state 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       100\n",
      "           1       0.93      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92   8]\n",
      " [  2 113]]\n",
      "random_state 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "random_state 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93       100\n",
      "           1       0.90      0.99      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 87  13]\n",
      " [  1 114]]\n",
      "random_state 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       100\n",
      "           1       0.90      0.98      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  2 113]]\n",
      "random_state 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       100\n",
      "           1       0.92      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  3 112]]\n",
      "random_state 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       100\n",
      "           1       0.92      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  3 112]]\n",
      "random_state 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       100\n",
      "           1       0.90      0.98      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.93      0.93      0.93       215\n",
      "\n",
      "[[ 87  13]\n",
      " [  2 113]]\n",
      "random_state 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       100\n",
      "           1       0.94      0.97      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  3 112]]\n",
      "random_state 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       100\n",
      "           1       0.90      0.98      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  2 113]]\n",
      "random_state 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  3 112]]\n",
      "random_state 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "random_state 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       100\n",
      "           1       0.92      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  2 113]]\n",
      "random_state 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       100\n",
      "           1       0.92      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  2 113]]\n",
      "random_state 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  1 114]]\n",
      "random_state 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       100\n",
      "           1       0.91      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  2 113]]\n",
      "random_state 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93       100\n",
      "           1       0.90      0.99      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 87  13]\n",
      " [  1 114]]\n",
      "random_state 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "random_state 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random_state 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       100\n",
      "           1       0.91      1.00      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 89  11]\n",
      " [  0 115]]\n",
      "random_state 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random_state 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "random_state 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for i in range(1,101):\n",
    "    dtc=DecisionTreeClassifier(random_state=i)\n",
    "    print('random_state',i)\n",
    "    dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04a87924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as running the decison tree  .concluded value is not increase  above 99 in recalll\n",
    "#so we can say that the model is predicted is 97 percent accurate in logistic Regression\n",
    "# the above data is clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c677f8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Information_Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.070372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.004012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.007650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.008586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.006017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.036105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.007909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.083249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.697304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.007716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.007985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>0.051771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Information_Gain\n",
       "0               radius_mean          0.000000\n",
       "1              texture_mean          0.000000\n",
       "2            perimeter_mean          0.000000\n",
       "3                 area_mean          0.000000\n",
       "4           smoothness_mean          0.000000\n",
       "5          compactness_mean          0.000000\n",
       "6            concavity_mean          0.000000\n",
       "7       concave points_mean          0.070372\n",
       "8             symmetry_mean          0.000000\n",
       "9    fractal_dimension_mean          0.000000\n",
       "10                radius_se          0.000000\n",
       "11               texture_se          0.004012\n",
       "12             perimeter_se          0.007650\n",
       "13                  area_se          0.008586\n",
       "14            smoothness_se          0.000000\n",
       "15           compactness_se          0.006017\n",
       "16             concavity_se          0.000000\n",
       "17        concave points_se          0.036105\n",
       "18              symmetry_se          0.000000\n",
       "19     fractal_dimension_se          0.007909\n",
       "20             radius_worst          0.007551\n",
       "21            texture_worst          0.083249\n",
       "22          perimeter_worst          0.697304\n",
       "23               area_worst          0.000000\n",
       "24         smoothness_worst          0.003772\n",
       "25        compactness_worst          0.007716\n",
       "26          concavity_worst          0.007985\n",
       "27     concave points_worst          0.000000\n",
       "28           symmetry_worst          0.051771\n",
       "29  fractal_dimension_worst          0.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat a dictanary   \n",
    "\n",
    "dict={\"Features\":X.columns,'Information_Gain':dtc.feature_importances_}\n",
    "\n",
    "\n",
    "df1=pd.DataFrame(dict)\n",
    "df1  #feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5523f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to overcome overfit we have 2 pruning technique\n",
    "#1 Max_depth\n",
    "#2 min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "039bea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     1.max_depth: inbuilt parameter of decision tree classifier class(minlen=1 and maxlen=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab87f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       100\n",
      "           1       0.95      0.94      0.94       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 94   6]\n",
      " [  7 108]]\n",
      "Max Depth 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       100\n",
      "           1       0.92      0.96      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.93      0.93      0.93       215\n",
      "weighted avg       0.93      0.93      0.93       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  5 110]]\n",
      "Max Depth 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n",
      "Max Depth 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       100\n",
      "           1       0.92      0.96      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  5 110]]\n",
      "Max Depth 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       100\n",
      "           1       0.92      0.97      0.94       115\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.94      0.93      0.93       215\n",
      "weighted avg       0.94      0.93      0.93       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  4 111]]\n",
      "Max Depth 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "Max Depth 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.95      0.94      0.94       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  3 112]]\n"
     ]
    }
   ],
   "source": [
    "# max depth parameter\n",
    "# create and object for DecisionTreeclassifier\n",
    "for i in range(1,9):\n",
    "    dtc1=DecisionTreeClassifier(random_state=1,max_depth=i)\n",
    "    print(\"Max Depth\",i)\n",
    "    dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fe05e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Information_Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.007773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.004042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.070897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.006736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.036374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.006062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.076409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.702507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.007608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>0.052157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Features  Information_Gain\n",
       "0               radius_mean          0.007773\n",
       "1              texture_mean          0.004042\n",
       "2            perimeter_mean          0.000000\n",
       "3                 area_mean          0.000000\n",
       "4           smoothness_mean          0.000000\n",
       "5          compactness_mean          0.000000\n",
       "6            concavity_mean          0.000000\n",
       "7       concave points_mean          0.070897\n",
       "8             symmetry_mean          0.000000\n",
       "9    fractal_dimension_mean          0.000000\n",
       "10                radius_se          0.000000\n",
       "11               texture_se          0.000000\n",
       "12             perimeter_se          0.006736\n",
       "13                  area_se          0.001915\n",
       "14            smoothness_se          0.000000\n",
       "15           compactness_se          0.000000\n",
       "16             concavity_se          0.000000\n",
       "17        concave points_se          0.036374\n",
       "18              symmetry_se          0.006062\n",
       "19     fractal_dimension_se          0.007968\n",
       "20             radius_worst          0.000000\n",
       "21            texture_worst          0.076409\n",
       "22          perimeter_worst          0.702507\n",
       "23               area_worst          0.007608\n",
       "24         smoothness_worst          0.003800\n",
       "25        compactness_worst          0.007707\n",
       "26          concavity_worst          0.008045\n",
       "27     concave points_worst          0.000000\n",
       "28           symmetry_worst          0.052157\n",
       "29  fractal_dimension_worst          0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dict1={\"Features\":X.columns,'Information_Gain':dtc1.feature_importances_}\n",
    "\n",
    "\n",
    "df2=pd.DataFrame(dict1)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95d24846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random_state 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n"
     ]
    }
   ],
   "source": [
    "#using meansample leaf\n",
    "for i in range(45,101):\n",
    "    dtc2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    print(\"random_state\",i)\n",
    "    dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "872d5496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89       100\n",
      "           1       0.86      0.99      0.92       115\n",
      "\n",
      "    accuracy                           0.91       215\n",
      "   macro avg       0.92      0.90      0.90       215\n",
      "weighted avg       0.92      0.91      0.91       215\n",
      "\n",
      "[[ 81  19]\n",
      " [  1 114]]\n",
      "Max Depth 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       100\n",
      "           1       0.98      0.96      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 98   2]\n",
      " [  5 110]]\n",
      "Max Depth 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       100\n",
      "           1       0.95      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 94   6]\n",
      " [  1 114]]\n",
      "Max Depth 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       100\n",
      "           1       0.96      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.97      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  0 115]]\n",
      "Max Depth 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "Max Depth 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "Max Depth 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "#using Entropy and Maxdepth\n",
    "for i in range(1,9):\n",
    "    dtc3=DecisionTreeClassifier(random_state=1,max_depth=i,criterion='entropy')\n",
    "    print(\"Max Depth\",i)\n",
    "    dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c52c0ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "dtc3=DecisionTreeClassifier(random_state=1,max_depth=6,criterion='entropy')\n",
    "dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "678a6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "Max Depth 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n"
     ]
    }
   ],
   "source": [
    "#using Entropy and Minsample\n",
    "for i in range(45,101):\n",
    "    dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=i,criterion='entropy')\n",
    "    print(\"Max Depth\",i)\n",
    "    dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a6c9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random State 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "random State 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "random State 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       100\n",
      "           1       0.97      0.97      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  3 112]]\n",
      "random State 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       100\n",
      "           1       0.97      0.97      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  3 112]]\n",
      "random State 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       100\n",
      "           1       0.97      0.97      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  3 112]]\n",
      "random State 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       100\n",
      "           1       0.96      0.96      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  5 110]]\n",
      "random State 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       100\n",
      "           1       0.96      0.96      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  5 110]]\n",
      "random State 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       100\n",
      "           1       0.96      0.96      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  5 110]]\n",
      "random State 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       100\n",
      "           1       0.94      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  4 111]]\n",
      "random State 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       100\n",
      "           1       0.94      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  4 111]]\n",
      "random State 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random State 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random State 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random State 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random State 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random State 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.95       215\n",
      "weighted avg       0.96      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  1 114]]\n",
      "random State 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "random State 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "random State 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "random State 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       100\n",
      "           1       0.96      0.97      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  4 111]]\n",
      "random State 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       100\n",
      "           1       0.99      0.94      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 99   1]\n",
      " [  7 108]]\n",
      "random State 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random State 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random State 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random State 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "random State 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,45):\n",
    "    dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=i,criterion='entropy')\n",
    "    print(\"random State\",i)\n",
    "    dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a0a69d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=1,criterion='entropy')\n",
    "dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e96df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Till now doing classification on DecisionTree classification ,accuary and recall value does not increases, only decision tree\n",
    "# and entropy showing and max depth (dtc3)\n",
    "# and dtc4 min samples (dtc4)  best accuary \n",
    "# # regression show best accuracy so far "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ffa9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using ensemble technique\n",
    "#ensemble techinque\n",
    "#ensemble technique:- train the dataset with mutliple algorithms and taking the combined score of all algorithms\n",
    "#bagging:- no of possibilities it will work on every possibility ,once the data is used it will use it again\n",
    "##pasting it does not work on every possibililties ,once the data is used it is not used again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5cf5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using randomForest Algoritms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "691e8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d09bad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9f75a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxfeatures  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       100\n",
      "           1       0.97      1.00      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.98      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 115]]\n",
      "Maxfeatures  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       100\n",
      "           1       0.96      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.97      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  0 115]]\n",
      "Maxfeatures  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       100\n",
      "           1       0.97      1.00      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.98      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 115]]\n",
      "Maxfeatures  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       100\n",
      "           1       0.97      1.00      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.98      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 115]]\n",
      "Maxfeatures  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "Maxfeatures  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "Maxfeatures  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "Maxfeatures  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       100\n",
      "           1       0.96      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.97      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  0 115]]\n",
      "Maxfeatures  9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       100\n",
      "           1       0.97      1.00      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.98      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 115]]\n",
      "Maxfeatures  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       100\n",
      "           1       0.97      1.00      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.98      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 115]]\n",
      "Maxfeatures  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       100\n",
      "           1       0.96      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.97      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  0 115]]\n",
      "Maxfeatures  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       100\n",
      "           1       0.97      0.99      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  1 114]]\n",
      "Maxfeatures  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n",
      "Maxfeatures  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       100\n",
      "           1       0.97      0.99      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  1 114]]\n",
      "Maxfeatures  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       100\n",
      "           1       0.97      0.99      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  1 114]]\n",
      "Maxfeatures  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       100\n",
      "           1       0.97      0.99      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  1 114]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    rfc=RandomForestClassifier(max_features=i,random_state=1)\n",
    "    print('Maxfeatures ',i)\n",
    "    rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23a9a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       100\n",
      "           1       0.97      1.00      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.98      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(random_state=1,max_features=1)\n",
    "rfc=create_model(rfc)  #best accuarcy in radom forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a0f9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using boosting technique to obtain optium score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa1a9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22de0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba973107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n estimator 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "n estimator 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       100\n",
      "           1       0.88      0.97      0.93       115\n",
      "\n",
      "    accuracy                           0.92       215\n",
      "   macro avg       0.92      0.91      0.91       215\n",
      "weighted avg       0.92      0.92      0.92       215\n",
      "\n",
      "[[ 85  15]\n",
      " [  3 112]]\n",
      "n estimator 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       100\n",
      "           1       0.93      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  3 112]]\n",
      "n estimator 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       100\n",
      "           1       0.90      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.95      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 88  12]\n",
      " [  1 114]]\n",
      "n estimator 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       100\n",
      "           1       0.92      0.99      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 90  10]\n",
      " [  1 114]]\n",
      "n estimator 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       100\n",
      "           1       0.93      0.98      0.95       115\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.95      0.95      0.95       215\n",
      "weighted avg       0.95      0.95      0.95       215\n",
      "\n",
      "[[ 91   9]\n",
      " [  2 113]]\n",
      "n estimator 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       100\n",
      "           1       0.95      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 94   6]\n",
      " [  1 114]]\n",
      "n estimator 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.94      0.98      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  2 113]]\n",
      "n estimator 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       100\n",
      "           1       0.94      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.97      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  1 114]]\n",
      "n estimator 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       100\n",
      "           1       0.95      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 94   6]\n",
      " [  1 114]]\n",
      "n estimator 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       100\n",
      "           1       0.95      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 94   6]\n",
      " [  1 114]]\n",
      "n estimator 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       100\n",
      "           1       0.96      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  1 114]]\n",
      "n estimator 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       100\n",
      "           1       0.93      0.99      0.96       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.96      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 92   8]\n",
      " [  1 114]]\n",
      "n estimator 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       100\n",
      "           1       0.94      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.96       215\n",
      "   macro avg       0.97      0.96      0.96       215\n",
      "weighted avg       0.96      0.96      0.96       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  1 114]]\n",
      "n estimator 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       100\n",
      "           1       0.96      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  1 114]]\n",
      "n estimator 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    ada=AdaBoostClassifier(random_state=1,n_estimators=i)\n",
    "    print(\"n estimator\",i)\n",
    "    ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b72b2c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.97      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.98      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "ada=AdaBoostClassifier(random_state=1,n_estimators=16)\n",
    "ada=create_model(ada) #best result in ADA boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5dff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b08e6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,40):\n",
    "#     gbc=GradientBoostingClassifier(random_state=1,n_estimators=i)\n",
    "#     print(\"No of estimators:\",i)\n",
    "#     gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aecbd65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       100\n",
      "           1       0.98      0.99      0.99       115\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.99      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n",
      "[[ 98   2]\n",
      " [  1 114]]\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=1,n_estimators=14)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59097b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96ea37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1174fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,100):\n",
    "#     xgb=XGBClassifier(random_state=1,n_estimators=i)\n",
    "#     print(\"n_estimators\",i)\n",
    "#     xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b1b377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       100\n",
      "           1       0.96      1.00      0.98       115\n",
      "\n",
      "    accuracy                           0.98       215\n",
      "   macro avg       0.98      0.97      0.98       215\n",
      "weighted avg       0.98      0.98      0.98       215\n",
      "\n",
      "[[ 95   5]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier(random_state=1,n_estimators=15)\n",
    "xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "889d75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1a14392",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "516c0452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm random state1 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n",
      "svm random state1 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    svm=SVC(random_state=i)\n",
    "    print(\"svm random state1\",i)\n",
    "    svm=create_model(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eba11b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.97      0.98      0.97       115\n",
      "\n",
      "    accuracy                           0.97       215\n",
      "   macro avg       0.97      0.97      0.97       215\n",
      "weighted avg       0.97      0.97      0.97       215\n",
      "\n",
      "[[ 96   4]\n",
      " [  2 113]]\n"
     ]
    }
   ],
   "source": [
    "svm=SVC(random_state=1,kernel='rbf',degree=4)\n",
    "svm=create_model(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e28dca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "797ca04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e3311a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1,26):\n",
    "gb = GaussianNB()\n",
    "    \n",
    "gb=create_model(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9e2f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       100\n",
      "           1       0.94      0.96      0.95       115\n",
      "\n",
      "    accuracy                           0.94       215\n",
      "   macro avg       0.94      0.94      0.94       215\n",
      "weighted avg       0.94      0.94      0.94       215\n",
      "\n",
      "[[ 93   7]\n",
      " [  5 110]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    gb = GaussianNB()\n",
    "    gb = create_model(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d94fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
